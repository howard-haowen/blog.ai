<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Adding a custom tokenizer to spaCy and extracting keywords | Haowen’s AI blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Adding a custom tokenizer to spaCy and extracting keywords" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This post shows how to plug in a custom tokenizer to spaCy and gets decent results for the extraction of keywords from texts in traditional Chinese." />
<meta property="og:description" content="This post shows how to plug in a custom tokenizer to spaCy and gets decent results for the extraction of keywords from texts in traditional Chinese." />
<link rel="canonical" href="https://howard-haowen.github.io/blog.ai/keyword-extraction/spacy/textacy/ckip-transformers/jieba/textrank/rake/2021/02/16/Adding-a-custom-tokenizer-to-spaCy-and-extracting-keywords.html" />
<meta property="og:url" content="https://howard-haowen.github.io/blog.ai/keyword-extraction/spacy/textacy/ckip-transformers/jieba/textrank/rake/2021/02/16/Adding-a-custom-tokenizer-to-spaCy-and-extracting-keywords.html" />
<meta property="og:site_name" content="Haowen’s AI blog" />
<meta property="og:image" content="https://howard-haowen.github.io/blog.ai/images/keywords.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-02-16T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"This post shows how to plug in a custom tokenizer to spaCy and gets decent results for the extraction of keywords from texts in traditional Chinese.","url":"https://howard-haowen.github.io/blog.ai/keyword-extraction/spacy/textacy/ckip-transformers/jieba/textrank/rake/2021/02/16/Adding-a-custom-tokenizer-to-spaCy-and-extracting-keywords.html","@type":"BlogPosting","headline":"Adding a custom tokenizer to spaCy and extracting keywords","dateModified":"2021-02-16T00:00:00-06:00","datePublished":"2021-02-16T00:00:00-06:00","image":"https://howard-haowen.github.io/blog.ai/images/keywords.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://howard-haowen.github.io/blog.ai/keyword-extraction/spacy/textacy/ckip-transformers/jieba/textrank/rake/2021/02/16/Adding-a-custom-tokenizer-to-spaCy-and-extracting-keywords.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog.ai/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://howard-haowen.github.io/blog.ai/feed.xml" title="Haowen's AI blog" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','G-46Y745KSM9','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/blog.ai/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog.ai/">Haowen&#39;s AI blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog.ai/about/">About Me</a><a class="page-link" href="/blog.ai/search/">Search</a><a class="page-link" href="/blog.ai/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Adding a custom tokenizer to spaCy and extracting keywords</h1><p class="page-description">This post shows how to plug in a custom tokenizer to spaCy and gets decent results for the extraction of keywords from texts in traditional Chinese.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-02-16T00:00:00-06:00" itemprop="datePublished">
        Feb 16, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      36 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog.ai/categories/#keyword-extraction">keyword-extraction</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog.ai/categories/#spacy">spacy</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog.ai/categories/#textacy">textacy</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog.ai/categories/#ckip-transformers">ckip-transformers</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog.ai/categories/#jieba">jieba</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog.ai/categories/#textrank">textrank</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog.ai/categories/#rake">rake</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/howard-haowen/blog.ai/tree/master/_notebooks/2021-02-16-Adding-a-custom-tokenizer-to-spaCy-and-extracting-keywords.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog.ai/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/howard-haowen/blog.ai/master?filepath=_notebooks%2F2021-02-16-Adding-a-custom-tokenizer-to-spaCy-and-extracting-keywords.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog.ai/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/howard-haowen/blog.ai/blob/master/_notebooks/2021-02-16-Adding-a-custom-tokenizer-to-spaCy-and-extracting-keywords.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog.ai/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Intro">Intro </a></li>
<li class="toc-entry toc-h1"><a href="#Working-pipeline">Working pipeline </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Set-variables">Set variables </a></li>
<li class="toc-entry toc-h2"><a href="#Preprocess-texts">Preprocess texts </a></li>
<li class="toc-entry toc-h2"><a href="#Install-spacy-and-ckip-transformers">Install spacy and ckip-transformers </a></li>
<li class="toc-entry toc-h2"><a href="#Tokenize-texts-with-ckip-transformers">Tokenize texts with ckip-transformers </a></li>
<li class="toc-entry toc-h2"><a href="#Feed-tokenized-results-to-spacy-using-WhitespaceTokenizer">Feed tokenized results to spacy using WhitespaceTokenizer </a></li>
<li class="toc-entry toc-h2"><a href="#Convert-stopwords-in-spaCy-from-simplified-to-Taiwanese-traditional">Convert stopwords in spaCy from simplified to Taiwanese traditional </a></li>
<li class="toc-entry toc-h2"><a href="#Define-a-class-for-implementing-TextRank">Define a class for implementing TextRank </a></li>
<li class="toc-entry toc-h2"><a href="#Put-it-together">Put it together </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Other-libraries-that-failed">Other libraries that failed </a>
<ul>
<li class="toc-entry toc-h2"><a href="#textaCy">textaCy </a></li>
<li class="toc-entry toc-h2"><a href="#pyate">pyate </a></li>
<li class="toc-entry toc-h2"><a href="#pytextrank">pytextrank </a></li>
<li class="toc-entry toc-h2"><a href="#rake-spacy">rake-spacy </a></li>
<li class="toc-entry toc-h2"><a href="#rake-keyword">rake-keyword </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Recap">Recap </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-02-16-Adding-a-custom-tokenizer-to-spaCy-and-extracting-keywords.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/howard-haowen/blog.ai/raw/master/images/keywords.png" alt="" title="Credit: Alex Hallatt"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Intro">
<a class="anchor" href="#Intro" aria-hidden="true"><span class="octicon octicon-link"></span></a>Intro<a class="anchor-link" href="#Intro"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>spaCy is an <code>industrial-strength natural language processing</code> library in Python, and supports multiple human languages, including Chinese. For segmenting Chinese texts into words, spaCy uses Jieba or PKUSeg under the hood. However, neither of them beats CKIP Transformers in accuracy when it comes to traditional Chinese (see my previous <a href="https://howard-haowen.github.io/blog.ai/tokenization/jieba/pkuseg/pyhanlp/snownlp/ckip-transformers/2021/01/29/Many-ways-to-segment-Chinese.html">post</a> for a comparison). So I'll show how to plug in CKIP Transformers to <code>spaCy</code> to get the best out of both.</p>
<p>For the purpose of demonstration, I'll situate this integration in a pipeline for extracting keywords from texts. Compared with other NLP tasks, keyword extraction is a relatively easy job. TextRank and RAKE seem to be among the most widely adopted algorithms for keyword extraction. I tried most of the methods mentioned in <a href="https://monkeylearn.com/keyword-extraction/">this article</a>, but there doesn't seem to be any easy-peasy implementation of TextRank or RAKE that produces decent results for traditional Chinese texts. So the first part of this post walks through a pipeline that actually works, and the second part records other methods that failed. I included the second part because I believe in this quote:</p>
<blockquote>
<p>“We learn wisdom from failure much more than from success. We often discover what will do, by finding out what will not do; and probably he who never made a mistake never made a discovery.” ― Samuel Smiles</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>TextRank is based on Google’s PageRank, which is used to compute the rank of webpages. This <a href="https://nlpforhackers.io/textrank-text-summarization/">article</a> on Natural Language Processing for Hackers demonstrates the connection between the two. From it I learned a tidbit: I always assumed that <code>Page</code> as in PageRank refers to webpages, but it turns out to be the family name of Larry Page, the creator of PageRank.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Working-pipeline">
<a class="anchor" href="#Working-pipeline" aria-hidden="true"><span class="octicon octicon-link"></span></a>Working pipeline<a class="anchor-link" href="#Working-pipeline"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Set-variables">
<a class="anchor" href="#Set-variables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Set variables<a class="anchor-link" href="#Set-variables"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's start with defining two variables that users of our keyword extraction program might want to modify: <code>CUSTOM_STOPWORDS</code> for a list of words that users definitely hope to exclude from keyword candidates and <code>KW_NUM</code> for the number of keywords that they'd like to extract from a document.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">CUSTOM_STOPWORDS</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="s2">"民眾"</span><span class="p">,</span><span class="s2">"朋友"</span><span class="p">,</span><span class="s2">"市民"</span><span class="p">,</span><span class="s2">"人數"</span><span class="p">,</span> <span class="s2">"全民"</span><span class="p">,</span><span class="s2">"人員"</span><span class="p">,</span><span class="s2">"人士"</span><span class="p">,</span><span class="s2">"里民"</span><span class="p">,</span>
                    <span class="s2">"影本"</span><span class="p">,</span><span class="s2">"系統"</span><span class="p">,</span> <span class="s2">"項目"</span><span class="p">,</span> <span class="s2">"證件"</span><span class="p">,</span> <span class="s2">"資格"</span><span class="p">,</span><span class="s2">"公民"</span><span class="p">,</span> <span class="s2">"對象"</span><span class="p">,</span><span class="s2">"個人"</span><span class="p">,</span>
                    <span class="p">]</span>

<span class="n">KW_NUM</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocess-texts">
<a class="anchor" href="#Preprocess-texts" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preprocess texts<a class="anchor-link" href="#Preprocess-texts"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I took an announcement from Land Administration Bureau of Kaohsiung City Goverment as a sample text, but you can basically take any text in traditional Chinese to test the program.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>To run the program with your own text, follow the following steps: 
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>Click on <code>Open in Colab</code> at the upper right corner of this page. </li>
<li>Click on <code>File</code> and then <code>Save a copy in Drive</code>.  </li>
<li>Replace the following text with your own text. </li>
<li>Click on <code>Runtime</code> and then <code>Run all</code>. </li>
<li>Go to the section <code>Put it together</code> to see the outcome. </li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_text</span> <span class="o">=</span> <span class="s1">'''</span>
<span class="s1">市府地政局109年度第4季開發區土地標售，共計推出8標9筆優質建地，訂於109年12月16日開標，合計總底價12 億4049萬6164 元。</span>

<span class="s1"> </span>

<span class="s1">第93期重劃區，原為國軍眷村，緊鄰國定古蹟-「原日本海軍鳳山無線電信所」，市府為保存古蹟同時活化眷村遷移後土地，以重劃方式整體開發，新闢住宅區、道路、公園及停車場，使本區具有歷史文化內涵與綠色休閒特色，生活機能更加健全。地政局首次推出1筆大面積土地，面積約2160坪，地形方整，雙面臨路，利於規劃興建景觀大樓，附近有市場、學校、公園及大東文化園區，距捷運大東站、鳳山國中站及鳳山火車站僅數分鐘車程，交通四通八達，因土地稀少性及區位條件絕佳，勢必成為投資人追逐焦點。</span>

<span class="s1"> </span>

<span class="s1">第87期重劃區，位於省道台1線旁，鄰近捷運南岡山站，重劃後擁有完善的道路系統、公園綠地及毗鄰醒村懷舊文化景觀建築群，具備優質居住環境及交通便捷要件，地政局一推出土地標售，即掀起搶標熱潮，本季再釋出1筆面積約93坪土地，臨20米介壽路及鵬程東路，附近有岡山文化中心、兆湘國小、公13、公14、陽明公園及劉厝公園，區位條件佳，投資人準備搶進！</span>

<span class="s1"> </span>

<span class="s1">第77期市地重劃區，位於鳳山區快速道路省道台88線旁，近中山高五甲系統交流道，近年推出土地標售皆順利完銷。本季再推出2筆土地，其中1筆面積約526坪，臨保華一路，適合商業使用；1筆面積107坪，位於代德三街，自用投資兩相宜。</span>

<span class="s1"> </span>

<span class="s1">高雄大學區段徵收區，為北高雄優質文教特區，優質居住環境，吸引投資人進駐，本季再推出2標2筆土地，其中1筆第三種商業區土地，面積約639坪，位於大學26街，近高雄大學正門及萬坪藍田公園，地形方正，使用強度高，適合興建優質住宅大樓；另1筆住三用地，面積約379坪，臨28米藍昌路，近高雄大學及中山高中，交通便捷。</span>

<span class="s1"> </span>

<span class="s1">另第37期重劃區及前大寮農地重劃區各推出1至2筆土地，價格合理。</span>

<span class="s1"> </span>

<span class="s1">第4季土地標售作業於109年12月1日公告，投資大眾可前往地政局土地開發處土地處分科索取標售海報及標單，或直接上網高雄房地產億年旺網站、地政局及土地開發處網站查詢下載相關資料，在期限前完成投標，另再提醒投標人，本年度已更新投標單格式，投標大眾請注意應以新式投標單投標以免投標無效作廢。</span>

<span class="s1"> </span>

<span class="s1">為配合防疫需求，本季開標作業除於地政局第一會議室辦理外，另將於地政局Facebook粉絲專頁同步直播，請大眾多加利用。</span>

<span class="s1"> </span>

<span class="s1">洽詢專線：(07)3373451或(07)3314942</span>

<span class="s1">高雄房地產億年旺網站（網址：http://eland.kcg.gov.tw/）</span>

<span class="s1">高雄市政府地政局網站（網址：http://landp.kcg.gov.tw/）</span>

<span class="s1">高雄市政府地政局土地開發處網站（網址：http://landevp.kcg.gov.tw/）　</span>
<span class="s1">'''</span>
<span class="n">raw_text</span><span class="p">[</span><span class="o">-</span><span class="mi">300</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'及土地開發處網站查詢下載相關資料，在期限前完成投標，另再提醒投標人，本年度已更新投標單格式，投標大眾請注意應以新式投標單投標以免投標無效作廢。\n\n \n\n為配合防疫需求，本季開標作業除於地政局第一會議室辦理外，另將於地政局Facebook粉絲專頁同步直播，請大眾多加利用。\n\n \n\n洽詢專線：(07)3373451或(07)3314942\n\n高雄房地產億年旺網站（網址：http://eland.kcg.gov.tw/）\n\n高雄市政府地政局網站（網址：http://landp.kcg.gov.tw/）\n\n高雄市政府地政局土地開發處網站（網址：http://landevp.kcg.gov.tw/）\u3000\n'</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I find this lightweight library <code>nlp2</code> quite handy for text cleaning. The <code>clean_all</code> function removes URL links, HTML elements, and unused tags.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>I want to give a shoutout to <a href="https://github.com/voidful">Eric Lam</a>, who created <code>nlp2</code> and other useful NLP tools such as <code>NLPrep</code>, <code>TFkit</code>, and <code>nlp2go</code>.   
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install nlp2
<span class="kn">from</span> <span class="nn">nlp2</span> <span class="kn">import</span> <span class="n">clean_all</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After cleaning, our sample text looks like this. Notice that all the URL links are gone now.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="n">clean_all</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="n">text</span><span class="p">[</span><span class="o">-</span><span class="mi">300</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'合理。\n\n \n\n第4季土地標售作業於109年12月1日公告，投資大眾可前往地政局土地開發處土地處分科索取標售海報及標單，或直接上網高雄房地產億年旺網站、地政局及土地開發處網站查詢下載相關資料，在期限前完成投標，另再提醒投標人，本年度已更新投標單格式，投標大眾請注意應以新式投標單投標以免投標無效作廢。\n\n \n\n為配合防疫需求，本季開標作業除於地政局第一會議室辦理外，另將於地政局Facebook粉絲專頁同步直播，請大眾多加利用。\n\n \n\n洽詢專線： 3373451或 3314942\n\n高雄房地產億年旺網站（網址： ）\n\n高雄市政府地政局網站（網址： ）\n\n高雄市政府地政局土地開發處網站（網址： ）'</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install-spacy-and-ckip-transformers">
<a class="anchor" href="#Install-spacy-and-ckip-transformers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Install <code>spacy</code> and <code>ckip-transformers</code><a class="anchor-link" href="#Install-spacy-and-ckip-transformers"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install -U pip setuptools wheel
<span class="o">!</span>pip install -U spacy
<span class="o">!</span>python -m spacy download zh_core_web_sm
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install -U ckip-transformers
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tokenize-texts-with-ckip-transformers">
<a class="anchor" href="#Tokenize-texts-with-ckip-transformers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tokenize texts with <code>ckip-transformers</code><a class="anchor-link" href="#Tokenize-texts-with-ckip-transformers"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's create a driver for word segmentation and one for parts of speech. CKIP Transformers also has a built-in driver for named entity recognition, i.e.  <code>CkipNerChunker</code>. But we won't use it here.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>By default, CPU is used. If you want to use GPU to speed up word segmentation, initialize <code>ws_driver</code> this way instead: <code>ws_driver = CkipWordSegmenter(device=-1)</code>
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ckip_transformers.nlp</span> <span class="kn">import</span> <span class="n">CkipWordSegmenter</span><span class="p">,</span> <span class="n">CkipPosTagger</span>
<span class="n">ws_driver</span>  <span class="o">=</span> <span class="n">CkipWordSegmenter</span><span class="p">()</span>
<span class="n">pos_driver</span> <span class="o">=</span> <span class="n">CkipPosTagger</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>Make sure that the input to <code>ws_driver()</code> is a list even if you’re only dealing with a single text. Otherwise, words won’t be properly segmented. Notice that the input to <code>pos_driver()</code> is the output of <code>ws_driver()</code>. 
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ws</span>  <span class="o">=</span> <span class="n">ws_driver</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">pos_driver</span><span class="p">(</span><span class="n">ws</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here're the segmented tokens.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">ws</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>['市府', '地政局', '109年度', '第4', '季', '開發區', '土地', '標售', '，', '共計', '推出', '8', '標', '9', '筆', '優質', '建地', '，', '訂', '於', '109年', '12月', '16日', '開標', '，', '合計', '總底價', '12 億', '4049萬', '6164 ', '元', '。', '\n\n \n\n', '第93', '期', '重劃區', '，', '原', '為', '國軍', '眷村', '，', '緊鄰', '國定', '古蹟', '-', '「', '原', '日本', '海軍', '鳳山', '無線', '電信所', '」', '，', '市府', '為', '保存', '古蹟', '同時', '活化', '眷村', '遷移', '後', '土地', '，', '以', '重劃', '方式', '整體', '開發', '，', '新', '闢', '住宅區', '、', '道路', '、', '公園', '及', '停車場', '，', '使', '本', '區', '具有', '歷史', '文化', '內涵', '與', '綠色', '休閒', '特色', '，', '生活', '機能', '更加', '健全', '。', '地政局', '首次', '推出', '1', '筆', '大', '面積', '土地', '，', '面積', '約', '2160', '坪', '，', '地形', '方整', '，', '雙面', '臨', '路', '，', '利於', '規劃', '興建', '景觀', '大樓', '，', '附近', '有', '市場', '、', '學校', '、', '公園', '及', '大東', '文化', '園區', '，', '距', '捷運', '大東站', '、', '鳳山', '國中站', '及', '鳳山', '火車站', '僅', '數', '分鐘', '車程', '，', '交通', '四通八達', '，', '因', '土地', '稀少性', '及', '區位', '條件', '絕佳', '，', '勢必', '成為', '投資人', '追逐', '焦點', '。', '\n\n \n\n', '第87', '期', '重劃區', '，', '位於', '省道', '台1線', '旁', '，', '鄰近', '捷運', '南', '岡山站', '，', '重劃', '後', '擁有', '完善', '的', '道路', '系統', '、', '公園', '綠地', '及', '毗鄰', '醒村', '懷舊', '文化', '景觀', '建築群', '，', '具備', '優質', '居住', '環境', '及', '交通', '便捷', '要件', '，', '地政局', '一', '推出', '土地', '標售', '，', '即', '掀起', '搶標', '熱潮', '，', '本', '季', '再', '釋出', '1', '筆', '面積', '約', '93', '坪', '土地', '，', '臨', '20', '米', '介壽路', '及', '鵬程東路', '，', '附近', '有', '岡山', '文化', '中心', '、', '兆湘', '國小', '、', '公13', '、', '公14', '、', '陽明', '公園', '及', '劉厝', '公園', '，', '區位', '條件', '佳', '，', '投資人', '準備', '搶進', '！', '\n\n \n\n', '第77', '期', '市地', '重劃區', '，', '位於', '鳳山區', '快速', '道路', '省道', '台88', '線', '旁', '，', '近', '中山高', '五甲', '系統', '交流道', '，', '近年', '推出', '土地', '標售', '皆', '順利', '完銷', '。', '本', '季', '再', '推出', '2', '筆', '土地', '，', '其中', '1', '筆', '面積', '約', '526', '坪', '，', '臨', '保華一路', '，', '適合', '商業', '使用', '；', '1', '筆', '面積', '107', '坪', '，', '位於', '代德三街', '，', '自用', '投資', '兩', '相宜', '。', '\n\n \n\n', '高雄', '大學', '區段', '徵收區', '，', '為', '北', '高雄', '優質', '文教', '特區', '，', '優質', '居住', '環境', '，', '吸引', '投資人', '進駐', '，', '本', '季', '再', '推出', '2', '標', '2', '筆', '土地', '，', '其中', '1', '筆', '第三', '種', '商業區', '土地', '，', '面積', '約', '639', '坪', '，', '位於', '大學', '26街', '，', '近', '高雄', '大學', '正門', '及', '萬', '坪', '藍田', '公園', '，', '地形', '方正', '，', '使用', '強度', '高', '，', '適合', '興建', '優質', '住宅', '大樓', '；', '另', '1', '筆', '住三', '用地', '，', '面積', '約', '379', '坪', '，', '臨', '28', '米', '藍昌路', '，', '近', '高雄', '大學', '及', '中山', '高中', '，', '交通', '便捷', '。', '\n\n \n\n', '另', '第37', '期', '重劃區', '及', '前', '大寮', '農地', '重劃區', '各', '推出', '1', '至', '2', '筆', '土地', '，', '價格', '合理', '。', '\n\n \n\n', '第4', '季', '土地', '標售', '作業', '於', '109年', '12月', '1日', '公告', '，', '投資', '大眾', '可', '前往', '地政局', '土地', '開發處', '土地處', '分科', '索取', '標售', '海報', '及', '標單', '，', '或', '直接', '上網', '高雄', '房地產', '億年旺', '網站', '、', '地政局', '及', '土地', '開發處', '網站', '查詢', '下載', '相關', '資料', '，', '在', '期限', '前', '完成', '投標', '，', '另', '再', '提醒', '投標人', '，', '本', '年度', '已', '更新', '投標單', '格式', '，', '投標', '大眾', '請', '注意', '應', '以', '新式', '投標單', '投標', '以免', '投標', '無效', '作廢', '。', '\n\n \n\n', '為', '配合', '防疫', '需求', '，', '本', '季', '開標', '作業', '除', '於', '地政局', '第一', '會議室', '辦理', '外', '，', '另', '將', '於', '地政局', 'Facebook', '粉絲', '專頁', '同步', '直播', '，', '請', '大眾', '多加', '利用', '。', '\n\n \n\n', '洽詢', '專線', '：', ' 3373', '451', '或', ' 3314942', '\n', '\n', '高雄', '房地產', '億', '年', '旺', '網站', '（', '網址', '：', ' ', '）', '\n', '\n', '高雄市', '政府', '地政局', '網站', '（', '網址', '：', ' ', '）', '\n', '\n', '高雄市', '政府', '地政局', '土地', '開發處', '網站', '（', '網址', '：', ' ', '）']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By contrast, Jieba produced lots of wrongly segmented tokens, which is precisely why we prefer CKIP Transformers.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">jieba</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">text</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 0.958 seconds.
Prefix dict has been built successfully.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>['市府', '地', '政局', '109', '年度', '第', '4', '季開', '發區', '土地', '標售', '，', '共計', '推出', '8', '標', '9', '筆優質', '建地', '，', '訂', '於', '109', '年', '12', '月', '16', '日', '開標', '，', '合計', '總底價', '12', ' ', '億', '4049', '萬', '6164', ' ', '元', '。', '\n', '\n', ' ', '\n', '\n', '第', '93', '期重', '劃區', '，', '原為國', '軍', '眷村', '，', '緊鄰', '國定', '古', '蹟', '-', '「', '原', '日本海', '軍鳳山', '無線', '電信', '所', '」', '，', '市府', '為', '保存', '古', '蹟', '同時', '活化', '眷村', '遷移', '後', '土地', '，', '以', '重劃', '方式', '整體', '開發', '，', '新闢', '住宅', '區', '、', '道路', '、', '公園', '及', '停車場', '，', '使本區', '具有', '歷史', '文化', '內涵', '與', '綠色', '休閒', '特色', '，', '生活', '機能', '更加', '健全', '。', '地', '政局', '首次', '推出', '1', '筆大面積', '土地', '，', '面積', '約', '2160', '坪', '，', '地形', '方整', '，', '雙面', '臨路', '，', '利', '於', '規劃', '興建景', '觀大樓', '，', '附近', '有', '市場', '、', '學校', '、', '公園', '及', '大東', '文化', '園區', '，', '距捷', '運大東', '站', '、', '鳳山國', '中站', '及鳳', '山火', '車站', '僅數', '分鐘', '車程', '，', '交通', '四通', '八達', '，', '因', '土地', '稀少', '性及', '區位', '條件', '絕佳', '，', '勢必成', '為', '投資人', '追逐', '焦點', '。', '\n', '\n', ' ', '\n', '\n', '第', '87', '期重', '劃區', '，', '位', '於', '省', '道', '台', '1', '線旁', '，', '鄰近', '捷運', '南岡山', '站', '，', '重劃', '後', '擁有', '完善', '的', '道路', '系統', '、', '公園', '綠地', '及', '毗', '鄰醒', '村懷舊', '文化', '景觀', '建築群', '，', '具備', '優質', '居住', '環境', '及', '交通', '便捷', '要件', '，', '地', '政局', '一', '推出', '土地', '標售', '，', '即', '掀起', '搶標', '熱潮', '，', '本季', '再釋', '出', '1', '筆面', '積約', '93', '坪', '土地', '，', '臨', '20', '米', '介壽路', '及鵬程', '東路', '，', '附近', '有岡山', '文化', '中心', '、', '兆', '湘國', '小', '、', '公', '13', '、', '公', '14', '、', '陽明', '公園', '及', '劉厝公園', '，', '區位', '條件', '佳', '，', '投資人', '準備', '搶進', '！', '\n', '\n', ' ', '\n', '\n', '第', '77', '期市', '地', '重劃區', '，', '位', '於', '鳳山區', '快速道路', '省道', '台', '88', '線旁', '，', '近', '中山', '高', '五甲', '系統', '交流', '道', '，', '近年', '推出', '土地', '標售', '皆', '順利', '完銷', '。', '本季', '再', '推出', '2', '筆', '土地', '，', '其中', '1', '筆面', '積約', '526', '坪', '，', '臨保華', '一路', '，', '適合', '商業', '使用', '；', '1', '筆面積', '107', '坪', '，', '位', '於', '代德三街', '，', '自用', '投資', '兩', '相宜', '。', '\n', '\n', ' ', '\n', '\n', '高雄', '大學區', '段', '徵收', '區', '，', '為', '北高雄', '優質', '文教', '特區', '，', '優質', '居住', '環境', '，', '吸引', '投資人', '進駐', '，', '本季', '再', '推出', '2', '標', '2', '筆', '土地', '，', '其中', '1', '筆', '第三', '種商業區', '土地', '，', '面積', '約', '639', '坪', '，', '位', '於', '大學', '26', '街', '，', '近高雄', '大學', '正門', '及', '萬坪', '藍田公園', '，', '地形', '方正', '，', '使用', '強度', '高', '，', '適合', '興建', '優質', '住宅', '大樓', '；', '另', '1', '筆住', '三', '用地', '，', '面積', '約', '379', '坪', '，', '臨', '28', '米', '藍昌路', '，', '近高雄', '大學及', '中山', '高中', '，', '交通', '便捷', '。', '\n', '\n', ' ', '\n', '\n', '另', '第', '37', '期重', '劃區', '及', '前', '大', '寮', '農地', '重劃區', '各', '推出', '1', '至', '2', '筆', '土地', '，', '價格', '合理', '。', '\n', '\n', ' ', '\n', '\n', '第', '4', '季', '土地', '標售', '作業', '於', '109', '年', '12', '月', '1', '日', '公告', '，', '投資大眾', '可', '前往', '地', '政局', '土地', '開發處', '土地', '處', '分科', '索取', '標售', '海報', '及', '標單', '，', '或', '直接', '上網', '高雄房', '地產', '億年', '旺', '網站', '、', '地', '政局', '及', '土地', '開發處', '網站', '查詢', '下載', '相關', '資料', '，', '在', '期限', '前', '完成', '投標', '，', '另', '再', '提醒', '投標', '人', '，', '本年度', '已', '更新', '投標', '單', '格式', '，', '投標', '大眾', '請', '注意', '應以', '新式', '投標單', '投標', '以免', '投標', '無效作', '廢', '。', '\n', '\n', ' ', '\n', '\n', '為', '配合', '防疫', '需求', '，', '本季', '開標', '作業', '除', '於', '地', '政局', '第一', '會議室', '辦理外', '，', '另將', '於', '地', '政局', 'Facebook', '粉絲', '專頁', '同步', '直播', '，', '請大眾', '多加', '利用', '。', '\n', '\n', ' ', '\n', '\n', '洽詢', '專線', '：', ' ', '3373451', '或', ' ', '3314942', '\n', '\n', '高雄房', '地產', '億年', '旺', '網站', '（', '網址', '：', ' ', '）', '\n', '\n', '高雄市', '政府', '地', '政局', '網站', '（', '網址', '：', ' ', '）', '\n', '\n', '高雄市', '政府', '地', '政局', '土地', '開發處', '網站', '（', '網址', '：', ' ', '）']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Feed-tokenized-results-to-spacy-using-WhitespaceTokenizer">
<a class="anchor" href="#Feed-tokenized-results-to-spacy-using-WhitespaceTokenizer" aria-hidden="true"><span class="octicon octicon-link"></span></a>Feed tokenized results to <code>spacy</code> using <code>WhitespaceTokenizer</code><a class="anchor-link" href="#Feed-tokenized-results-to-spacy-using-WhitespaceTokenizer"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <a href="https://spacy.io/usage/linguistic-features#native-tokenizers">official website of spaCy</a> describes several ways of adding a custom tokenizer. The simplest is to define the  <code>WhitespaceTokenizer</code> class, which tokenizes a text on space characters. The output of tokenization can then be fed into subsequent operations down the pipeline, including <code>tagger</code> for parts-of-speech (POS) tagging, <code>parser</code> for dependency parsing, and <code>ner</code> for named entity recognition. This is possible primarily because <code>tokenizer</code> creates a <code>Doc</code> object whereas the other three steps operate on the <code>Doc</code> object, as illustrated in this graph. 
<img src="https://spacy.io/pipeline-fde48da9b43661abcdf62ab70a546d71.svg" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>The original code for <code>words</code> is <code>words = text.split(" ")</code>, but it caused an error to my text. So I revised it into <code>words = text.strip().split()</code>. 
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">spacy.tokens</span> <span class="kn">import</span> <span class="n">Doc</span>

<span class="k">class</span> <span class="nc">WhitespaceTokenizer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">Doc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">words</span><span class="o">=</span><span class="n">words</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, let's load the <code>zh_core_web_sm</code> model for Chinese, which we'll need for POS tagging. Then here comes the crucial part: <code>nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)</code>. This line of code sets the default tokenizer from Jieba to <code>WhitespaceTokenizer</code>, which we just defined above.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'zh_core_web_sm'</span><span class="p">)</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">WhitespaceTokenizer</span><span class="p">(</span><span class="n">nlp</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then we join the tokenized result from CKIP Transformers to a single string of space-seperated tokens.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">token_str</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="n">token_str</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'市府 地政局 109年度 第4 季 開發區 土地 標售 ， 共計 推出 8 標 9 筆 優質 建地 ， 訂 於 109年 12月 16日 開標 ， 合計 總底價 12 億 4049萬 6164  元 。 \n\n \n\n 第93 期 重劃區 ， 原 為 國軍 眷村 ， 緊鄰 國定 古蹟 - 「 原 日本 海軍 鳳山 無線 電信所 」 ， 市府 為 保存 古蹟 同時 活化 眷村 遷移 後 土地 ， 以 重劃 方式 整體 開發 ， 新 闢 住宅區 、 道路 、 公園 及 停車場 ， 使 本 區 具有 歷史 文化 內涵 與 綠色 休閒 特色 ， 生活 機能 更加 健全 。 地政局 首次 推出 1 筆 大 面積 土地 ， 面積 約 2160 坪 ， 地形 方整 ， 雙面 臨 路 ， 利於 規劃 興建 景觀 大樓 ， 附近 有 市場 、 學校 、 公園 及 大東 文化 園區 ， 距 捷運 大東站 、 鳳山 國中站 及 鳳山 火車站 僅 數 分鐘 車程 ， 交通 四通八達 ， 因 土地 稀少性 及 區位 條件 絕佳 ， 勢必 成為 投資人 追逐 焦點 。 \n\n \n\n 第87 期 重劃區 ， 位於 省道 台1線 旁 ， 鄰近 捷運 南 岡山站 ， 重劃 後 擁有 完善 的 道路 系統 、 公園 綠地 及 毗鄰 醒村 懷舊 文化 景觀 建築群 ， 具備 優質 居住 環境 及 交通 便捷 要件 ， 地政局 一 推出 土地 標售 ， 即 掀起 搶標 熱潮 ， 本 季 再 釋出 1 筆 面積 約 93 坪 土地 ， 臨 20 米 介壽路 及 鵬程東路 ， 附近 有 岡山 文化 中心 、 兆湘 國小 、 公13 、 公14 、 陽明 公園 及 劉厝 公園 ， 區位 條件 佳 ， 投資人 準備 搶進 ！ \n\n \n\n 第77 期 市地 重劃區 ， 位於 鳳山區 快速 道路 省道 台88 線 旁 ， 近 中山高 五甲 系統 交流道 ， 近年 推出 土地 標售 皆 順利 完銷 。 本 季 再 推出 2 筆 土地 ， 其中 1 筆 面積 約 526 坪 ， 臨 保華一路 ， 適合 商業 使用 ； 1 筆 面積 107 坪 ， 位於 代德三街 ， 自用 投資 兩 相宜 。 \n\n \n\n 高雄 大學 區段 徵收區 ， 為 北 高雄 優質 文教 特區 ， 優質 居住 環境 ， 吸引 投資人 進駐 ， 本 季 再 推出 2 標 2 筆 土地 ， 其中 1 筆 第三 種 商業區 土地 ， 面積 約 639 坪 ， 位於 大學 26街 ， 近 高雄 大學 正門 及 萬 坪 藍田 公園 ， 地形 方正 ， 使用 強度 高 ， 適合 興建 優質 住宅 大樓 ； 另 1 筆 住三 用地 ， 面積 約 379 坪 ， 臨 28 米 藍昌路 ， 近 高雄 大學 及 中山 高中 ， 交通 便捷 。 \n\n \n\n 另 第37 期 重劃區 及 前 大寮 農地 重劃區 各 推出 1 至 2 筆 土地 ， 價格 合理 。 \n\n \n\n 第4 季 土地 標售 作業 於 109年 12月 1日 公告 ， 投資 大眾 可 前往 地政局 土地 開發處 土地處 分科 索取 標售 海報 及 標單 ， 或 直接 上網 高雄 房地產 億年旺 網站 、 地政局 及 土地 開發處 網站 查詢 下載 相關 資料 ， 在 期限 前 完成 投標 ， 另 再 提醒 投標人 ， 本 年度 已 更新 投標單 格式 ， 投標 大眾 請 注意 應 以 新式 投標單 投標 以免 投標 無效 作廢 。 \n\n \n\n 為 配合 防疫 需求 ， 本 季 開標 作業 除 於 地政局 第一 會議室 辦理 外 ， 另 將 於 地政局 Facebook 粉絲 專頁 同步 直播 ， 請 大眾 多加 利用 。 \n\n \n\n 洽詢 專線 ：  3373 451 或  3314942 \n \n 高雄 房地產 億 年 旺 網站 （ 網址 ：   ） \n \n 高雄市 政府 地政局 網站 （ 網址 ：   ） \n \n 高雄市 政府 地政局 土地 開發處 網站 （ 網址 ：   ）'</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we feed <code>token_str</code>, our tokenized text, to <code>nlp</code> to create a spaCy <code>Doc</code> object. From this point on, we are able to leverage the power of spaCy. For every token in a <code>Doc</code> object, we have access to its text via the attribute <code>.text</code> and its parts-of-speech label via the attribute <code>.pos_</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">token_str</span><span class="p">)</span>
<span class="nb">print</span><span class="p">([</span><span class="n">token</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">])</span>
<span class="nb">print</span><span class="p">([</span><span class="n">token</span><span class="o">.</span><span class="n">pos_</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>['市府', '地政局', '109年度', '第4', '季', '開發區', '土地', '標售', '，', '共計', '推出', '8', '標', '9', '筆', '優質', '建地', '，', '訂', '於', '109年', '12月', '16日', '開標', '，', '合計', '總底價', '12', '億', '4049萬', '6164', '元', '。', '第93', '期', '重劃區', '，', '原', '為', '國軍', '眷村', '，', '緊鄰', '國定', '古蹟', '-', '「', '原', '日本', '海軍', '鳳山', '無線', '電信所', '」', '，', '市府', '為', '保存', '古蹟', '同時', '活化', '眷村', '遷移', '後', '土地', '，', '以', '重劃', '方式', '整體', '開發', '，', '新', '闢', '住宅區', '、', '道路', '、', '公園', '及', '停車場', '，', '使', '本', '區', '具有', '歷史', '文化', '內涵', '與', '綠色', '休閒', '特色', '，', '生活', '機能', '更加', '健全', '。', '地政局', '首次', '推出', '1', '筆', '大', '面積', '土地', '，', '面積', '約', '2160', '坪', '，', '地形', '方整', '，', '雙面', '臨', '路', '，', '利於', '規劃', '興建', '景觀', '大樓', '，', '附近', '有', '市場', '、', '學校', '、', '公園', '及', '大東', '文化', '園區', '，', '距', '捷運', '大東站', '、', '鳳山', '國中站', '及', '鳳山', '火車站', '僅', '數', '分鐘', '車程', '，', '交通', '四通八達', '，', '因', '土地', '稀少性', '及', '區位', '條件', '絕佳', '，', '勢必', '成為', '投資人', '追逐', '焦點', '。', '第87', '期', '重劃區', '，', '位於', '省道', '台1線', '旁', '，', '鄰近', '捷運', '南', '岡山站', '，', '重劃', '後', '擁有', '完善', '的', '道路', '系統', '、', '公園', '綠地', '及', '毗鄰', '醒村', '懷舊', '文化', '景觀', '建築群', '，', '具備', '優質', '居住', '環境', '及', '交通', '便捷', '要件', '，', '地政局', '一', '推出', '土地', '標售', '，', '即', '掀起', '搶標', '熱潮', '，', '本', '季', '再', '釋出', '1', '筆', '面積', '約', '93', '坪', '土地', '，', '臨', '20', '米', '介壽路', '及', '鵬程東路', '，', '附近', '有', '岡山', '文化', '中心', '、', '兆湘', '國小', '、', '公13', '、', '公14', '、', '陽明', '公園', '及', '劉厝', '公園', '，', '區位', '條件', '佳', '，', '投資人', '準備', '搶進', '！', '第77', '期', '市地', '重劃區', '，', '位於', '鳳山區', '快速', '道路', '省道', '台88', '線', '旁', '，', '近', '中山高', '五甲', '系統', '交流道', '，', '近年', '推出', '土地', '標售', '皆', '順利', '完銷', '。', '本', '季', '再', '推出', '2', '筆', '土地', '，', '其中', '1', '筆', '面積', '約', '526', '坪', '，', '臨', '保華一路', '，', '適合', '商業', '使用', '；', '1', '筆', '面積', '107', '坪', '，', '位於', '代德三街', '，', '自用', '投資', '兩', '相宜', '。', '高雄', '大學', '區段', '徵收區', '，', '為', '北', '高雄', '優質', '文教', '特區', '，', '優質', '居住', '環境', '，', '吸引', '投資人', '進駐', '，', '本', '季', '再', '推出', '2', '標', '2', '筆', '土地', '，', '其中', '1', '筆', '第三', '種', '商業區', '土地', '，', '面積', '約', '639', '坪', '，', '位於', '大學', '26街', '，', '近', '高雄', '大學', '正門', '及', '萬', '坪', '藍田', '公園', '，', '地形', '方正', '，', '使用', '強度', '高', '，', '適合', '興建', '優質', '住宅', '大樓', '；', '另', '1', '筆', '住三', '用地', '，', '面積', '約', '379', '坪', '，', '臨', '28', '米', '藍昌路', '，', '近', '高雄', '大學', '及', '中山', '高中', '，', '交通', '便捷', '。', '另', '第37', '期', '重劃區', '及', '前', '大寮', '農地', '重劃區', '各', '推出', '1', '至', '2', '筆', '土地', '，', '價格', '合理', '。', '第4', '季', '土地', '標售', '作業', '於', '109年', '12月', '1日', '公告', '，', '投資', '大眾', '可', '前往', '地政局', '土地', '開發處', '土地處', '分科', '索取', '標售', '海報', '及', '標單', '，', '或', '直接', '上網', '高雄', '房地產', '億年旺', '網站', '、', '地政局', '及', '土地', '開發處', '網站', '查詢', '下載', '相關', '資料', '，', '在', '期限', '前', '完成', '投標', '，', '另', '再', '提醒', '投標人', '，', '本', '年度', '已', '更新', '投標單', '格式', '，', '投標', '大眾', '請', '注意', '應', '以', '新式', '投標單', '投標', '以免', '投標', '無效', '作廢', '。', '為', '配合', '防疫', '需求', '，', '本', '季', '開標', '作業', '除', '於', '地政局', '第一', '會議室', '辦理', '外', '，', '另', '將', '於', '地政局', 'Facebook', '粉絲', '專頁', '同步', '直播', '，', '請', '大眾', '多加', '利用', '。', '洽詢', '專線', '：', '3373', '451', '或', '3314942', '高雄', '房地產', '億', '年', '旺', '網站', '（', '網址', '：', '）', '高雄市', '政府', '地政局', '網站', '（', '網址', '：', '）', '高雄市', '政府', '地政局', '土地', '開發處', '網站', '（', '網址', '：', '）']
['NOUN', 'NOUN', 'NUM', 'NUM', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PUNCT', 'VERB', 'VERB', 'NUM', 'CCONJ', 'NUM', 'ADV', 'VERB', 'NOUN', 'PUNCT', 'ADV', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'PUNCT', 'NOUN', 'NOUN', 'NUM', 'PROPN', 'NOUN', 'NUM', 'NUM', 'PUNCT', 'NUM', 'NUM', 'NOUN', 'PUNCT', 'ADV', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'NOUN', 'VERB', 'PROPN', 'PUNCT', 'PUNCT', 'ADJ', 'PROPN', 'NOUN', 'VERB', 'ADV', 'NOUN', 'PUNCT', 'PUNCT', 'NOUN', 'VERB', 'VERB', 'PROPN', 'VERB', 'VERB', 'NOUN', 'NOUN', 'PART', 'NOUN', 'PUNCT', 'ADP', 'NOUN', 'NOUN', 'ADV', 'NOUN', 'PUNCT', 'ADV', 'VERB', 'NOUN', 'PUNCT', 'NOUN', 'PUNCT', 'NOUN', 'CCONJ', 'NOUN', 'PUNCT', 'VERB', 'DET', 'NUM', 'VERB', 'NOUN', 'NOUN', 'VERB', 'ADV', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'NOUN', 'NOUN', 'ADV', 'VERB', 'PUNCT', 'NOUN', 'ADV', 'VERB', 'NUM', 'NUM', 'ADJ', 'NOUN', 'NOUN', 'PUNCT', 'VERB', 'NOUN', 'NUM', 'NUM', 'PUNCT', 'NOUN', 'NOUN', 'PUNCT', 'VERB', 'NUM', 'NOUN', 'PUNCT', 'NOUN', 'PROPN', 'NOUN', 'NOUN', 'NOUN', 'PUNCT', 'NOUN', 'VERB', 'NOUN', 'PUNCT', 'NOUN', 'PUNCT', 'NOUN', 'CCONJ', 'ADJ', 'NOUN', 'NOUN', 'PUNCT', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'NOUN', 'NOUN', 'CCONJ', 'VERB', 'NOUN', 'PROPN', 'NOUN', 'VERB', 'NOUN', 'PUNCT', 'NOUN', 'NUM', 'PUNCT', 'ADP', 'NOUN', 'NOUN', 'CCONJ', 'NOUN', 'ADV', 'VERB', 'PUNCT', 'VERB', 'NOUN', 'NOUN', 'VERB', 'NOUN', 'PUNCT', 'NUM', 'NUM', 'NOUN', 'PUNCT', 'ADJ', 'NOUN', 'NOUN', 'PART', 'PUNCT', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'PUNCT', 'NOUN', 'PART', 'NOUN', 'VERB', 'PART', 'NOUN', 'NOUN', 'PUNCT', 'NOUN', 'NOUN', 'CCONJ', 'VERB', 'PROPN', 'NOUN', 'NOUN', 'PROPN', 'NOUN', 'PUNCT', 'VERB', 'PROPN', 'NOUN', 'NOUN', 'CCONJ', 'NOUN', 'NOUN', 'NOUN', 'PUNCT', 'NOUN', 'ADV', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'ADV', 'VERB', 'ADJ', 'NOUN', 'PUNCT', 'DET', 'NOUN', 'ADV', 'NOUN', 'NUM', 'NUM', 'VERB', 'NOUN', 'NUM', 'NUM', 'NOUN', 'PUNCT', 'VERB', 'NUM', 'NUM', 'NOUN', 'CCONJ', 'VERB', 'PUNCT', 'NOUN', 'VERB', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'ADJ', 'NOUN', 'PUNCT', 'NOUN', 'PUNCT', 'PROPN', 'PUNCT', 'NOUN', 'NOUN', 'CCONJ', 'NOUN', 'NOUN', 'PUNCT', 'NOUN', 'VERB', 'VERB', 'PUNCT', 'VERB', 'VERB', 'NOUN', 'PUNCT', 'NUM', 'NUM', 'NOUN', 'NOUN', 'PUNCT', 'ADJ', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PART', 'PUNCT', 'ADV', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'PUNCT', 'NOUN', 'VERB', 'NOUN', 'NOUN', 'ADV', 'NOUN', 'VERB', 'PUNCT', 'DET', 'NOUN', 'ADV', 'VERB', 'NUM', 'NUM', 'NOUN', 'PUNCT', 'NOUN', 'NUM', 'NUM', 'VERB', 'NOUN', 'NUM', 'NUM', 'PUNCT', 'NOUN', 'NOUN', 'PUNCT', 'PROPN', 'NOUN', 'VERB', 'PUNCT', 'NUM', 'NUM', 'VERB', 'NUM', 'NUM', 'PUNCT', 'NOUN', 'VERB', 'PUNCT', 'VERB', 'VERB', 'NOUN', 'VERB', 'PUNCT', 'PROPN', 'NOUN', 'VERB', 'NOUN', 'PUNCT', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'NOUN', 'NOUN', 'PUNCT', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'DET', 'NOUN', 'ADV', 'VERB', 'NUM', 'ADJ', 'NUM', 'NUM', 'NOUN', 'PUNCT', 'NOUN', 'NUM', 'NOUN', 'NUM', 'CCONJ', 'NOUN', 'NOUN', 'PUNCT', 'VERB', 'NOUN', 'NUM', 'NUM', 'PUNCT', 'ADJ', 'NOUN', 'NOUN', 'PUNCT', 'ADJ', 'PROPN', 'NOUN', 'NOUN', 'CCONJ', 'NUM', 'NUM', 'ADJ', 'NOUN', 'PUNCT', 'NOUN', 'VERB', 'PUNCT', 'VERB', 'NOUN', 'VERB', 'PUNCT', 'ADV', 'NOUN', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'DET', 'NUM', 'NOUN', 'VERB', 'VERB', 'PUNCT', 'VERB', 'NOUN', 'NUM', 'NUM', 'PUNCT', 'VERB', 'NUM', 'NUM', 'NOUN', 'PUNCT', 'ADJ', 'PROPN', 'NOUN', 'CCONJ', 'PROPN', 'NOUN', 'PUNCT', 'NOUN', 'VERB', 'PUNCT', 'DET', 'NUM', 'NUM', 'NOUN', 'CCONJ', 'ADJ', 'ADJ', 'NOUN', 'NOUN', 'ADV', 'VERB', 'NUM', 'CCONJ', 'NUM', 'NUM', 'NOUN', 'PUNCT', 'NOUN', 'VERB', 'PUNCT', 'NUM', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'PUNCT', 'VERB', 'NOUN', 'VERB', 'VERB', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'VERB', 'VERB', 'NOUN', 'CCONJ', 'NOUN', 'PUNCT', 'CCONJ', 'ADV', 'NOUN', 'PROPN', 'NOUN', 'NOUN', 'VERB', 'PUNCT', 'NOUN', 'CCONJ', 'NOUN', 'NOUN', 'ADV', 'VERB', 'VERB', 'VERB', 'VERB', 'PUNCT', 'ADP', 'NOUN', 'PART', 'VERB', 'NOUN', 'PUNCT', 'ADV', 'ADV', 'VERB', 'NOUN', 'PUNCT', 'DET', 'NOUN', 'ADV', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'VERB', 'PROPN', 'ADV', 'VERB', 'VERB', 'ADP', 'ADJ', 'NOUN', 'VERB', 'ADV', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'VERB', 'VERB', 'NOUN', 'NOUN', 'PUNCT', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'ADP', 'NOUN', 'NUM', 'NOUN', 'NOUN', 'PART', 'PUNCT', 'DET', 'ADV', 'VERB', 'NOUN', 'PROPN', 'PROPN', 'ADV', 'ADV', 'VERB', 'PUNCT', 'VERB', 'PROPN', 'VERB', 'NOUN', 'PUNCT', 'NOUN', 'NOUN', 'PUNCT', 'NUM', 'NOUN', 'CCONJ', 'NUM', 'PROPN', 'NOUN', 'NUM', 'NUM', 'VERB', 'VERB', 'PUNCT', 'VERB', 'PUNCT', 'PUNCT', 'PROPN', 'NOUN', 'NOUN', 'VERB', 'PUNCT', 'VERB', 'PUNCT', 'PUNCT', 'PROPN', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'PUNCT', 'VERB', 'PUNCT', 'PUNCT']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The POS tagging is made possible by the <code>zh_core_web_sm</code> model. Notice that spaCy uses coarse labels such as <code>NOUN</code> and <code>VERB</code>. By contrast, CKIP Transformers adopts a more fine-grained tagset, such as <code>Nc</code> for locative nouns and <code>Nd</code> for temporal nouns. Here're the POS labels for the same text produced by CKIP Transformers. We'll be using the spaCy's POS tagging to filter out words that we don't want in the candicate pool for keywords.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pos_tags</span> <span class="o">=</span> <span class="n">pos</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pos_tags</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>['Nc', 'Nc', 'Nd', 'Neu', 'Nd', 'Nc', 'Na', 'VC', 'COMMACATEGORY', 'VJ', 'VC', 'Neu', 'Nf', 'Neu', 'Nf', 'A', 'Na', 'COMMACATEGORY', 'VJ', 'P', 'Nd', 'Nd', 'Nd', 'VA', 'COMMACATEGORY', 'VG', 'Na', 'Neu', 'Neu', 'Neu', 'Nf', 'PERIODCATEGORY', 'WHITESPACE', 'Neu', 'Nf', 'Nc', 'COMMACATEGORY', 'D', 'VG', 'Na', 'Nc', 'COMMACATEGORY', 'VJ', 'A', 'Na', 'DASHCATEGORY', 'PARENTHESISCATEGORY', 'A', 'Nc', 'Nc', 'Nc', 'A', 'Nc', 'PARENTHESISCATEGORY', 'COMMACATEGORY', 'Nc', 'P', 'VC', 'Na', 'Nd', 'VHC', 'Nc', 'VC', 'Ng', 'Na', 'COMMACATEGORY', 'P', 'Nv', 'Na', 'Na', 'VC', 'COMMACATEGORY', 'VH', 'VC', 'Nc', 'PAUSECATEGORY', 'Na', 'PAUSECATEGORY', 'Nc', 'Caa', 'Nc', 'COMMACATEGORY', 'VL', 'Nes', 'Nc', 'VJ', 'Na', 'Na', 'Na', 'Caa', 'Na', 'Nv', 'Na', 'COMMACATEGORY', 'Na', 'Na', 'Dfa', 'VHC', 'PERIODCATEGORY', 'Nc', 'D', 'VC', 'Neu', 'Nf', 'VH', 'Na', 'Na', 'COMMACATEGORY', 'Na', 'Da', 'Neu', 'Nf', 'COMMACATEGORY', 'Na', 'VH', 'COMMACATEGORY', 'A', 'VCL', 'Na', 'COMMACATEGORY', 'VK', 'VC', 'VC', 'Na', 'Na', 'COMMACATEGORY', 'Nc', 'V_2', 'Nc', 'PAUSECATEGORY', 'Nc', 'PAUSECATEGORY', 'Nc', 'Caa', 'Nb', 'Na', 'Nc', 'COMMACATEGORY', 'P', 'Na', 'Nc', 'PAUSECATEGORY', 'Nc', 'Nc', 'Caa', 'Nc', 'Nc', 'Da', 'Neu', 'Nf', 'Na', 'COMMACATEGORY', 'Na', 'VH', 'COMMACATEGORY', 'Cbb', 'Na', 'Na', 'Caa', 'Na', 'Na', 'VH', 'COMMACATEGORY', 'D', 'VG', 'Na', 'VC', 'Na', 'PERIODCATEGORY', 'WHITESPACE', 'Neu', 'Nf', 'Nc', 'COMMACATEGORY', 'VCL', 'Nc', 'Nc', 'Ncd', 'COMMACATEGORY', 'VJ', 'Na', 'Nc', 'Nc', 'COMMACATEGORY', 'VC', 'Ng', 'VJ', 'VH', 'DE', 'Na', 'Na', 'PAUSECATEGORY', 'Nc', 'Na', 'Caa', 'VH', 'Nc', 'VH', 'Na', 'Na', 'Na', 'COMMACATEGORY', 'VJ', 'A', 'VA', 'Na', 'Caa', 'Na', 'VH', 'Na', 'COMMACATEGORY', 'Nc', 'D', 'VC', 'Na', 'Nv', 'COMMACATEGORY', 'D', 'VC', 'VD', 'Na', 'COMMACATEGORY', 'Nes', 'Nd', 'D', 'VC', 'Neu', 'Nf', 'Na', 'Da', 'Neu', 'Nf', 'Na', 'COMMACATEGORY', 'P', 'Neu', 'Nf', 'Nc', 'Caa', 'Nc', 'COMMACATEGORY', 'Nc', 'V_2', 'Nc', 'Na', 'Nc', 'PAUSECATEGORY', 'Nb', 'Nc', 'PAUSECATEGORY', 'Na', 'PAUSECATEGORY', 'Na', 'PAUSECATEGORY', 'Nb', 'Nc', 'Caa', 'Nc', 'Nc', 'COMMACATEGORY', 'Na', 'Na', 'VH', 'COMMACATEGORY', 'Na', 'VF', 'VA', 'EXCLAMATIONCATEGORY', 'WHITESPACE', 'Neu', 'Nf', 'Na', 'Nc', 'COMMACATEGORY', 'VCL', 'Nc', 'VH', 'Na', 'Nc', 'Nc', 'Nf', 'Ncd', 'COMMACATEGORY', 'VJ', 'Nc', 'Nc', 'Na', 'Na', 'COMMACATEGORY', 'Nd', 'VC', 'Na', 'Nv', 'D', 'VH', 'VC', 'PERIODCATEGORY', 'Nes', 'Nd', 'D', 'VC', 'Neu', 'Nf', 'Na', 'COMMACATEGORY', 'Nep', 'Neu', 'Nf', 'Na', 'Da', 'Neu', 'Nf', 'COMMACATEGORY', 'P', 'Nc', 'COMMACATEGORY', 'VH', 'Na', 'VC', 'SEMICOLONCATEGORY', 'Neu', 'Nf', 'Na', 'Neu', 'Nf', 'COMMACATEGORY', 'VCL', 'Nc', 'COMMACATEGORY', 'A', 'Na', 'Neu', 'VH', 'PERIODCATEGORY', 'WHITESPACE', 'Nc', 'Nc', 'Na', 'VC', 'COMMACATEGORY', 'VG', 'Ncd', 'Nc', 'A', 'Na', 'Nc', 'COMMACATEGORY', 'A', 'Nv', 'Na', 'COMMACATEGORY', 'VJ', 'Na', 'VCL', 'COMMACATEGORY', 'Nes', 'Nd', 'D', 'VC', 'Neu', 'Nf', 'Neu', 'Nf', 'Na', 'COMMACATEGORY', 'Nep', 'Neu', 'Nf', 'Neu', 'Nf', 'Nc', 'Na', 'COMMACATEGORY', 'Na', 'Da', 'Neu', 'Nf', 'COMMACATEGORY', 'VCL', 'Nc', 'Nc', 'COMMACATEGORY', 'VH', 'Nc', 'Nc', 'Na', 'Caa', 'Neu', 'Nf', 'Nb', 'Nc', 'COMMACATEGORY', 'Na', 'VH', 'COMMACATEGORY', 'Nv', 'Na', 'VH', 'COMMACATEGORY', 'VH', 'VC', 'A', 'Na', 'Na', 'SEMICOLONCATEGORY', 'Nes', 'Neu', 'Nf', 'VCL', 'Na', 'COMMACATEGORY', 'Na', 'Da', 'Neu', 'Nf', 'COMMACATEGORY', 'P', 'Neu', 'Nf', 'Nc', 'COMMACATEGORY', 'VH', 'Nc', 'Nc', 'Caa', 'Nb', 'Nc', 'COMMACATEGORY', 'Na', 'VH', 'PERIODCATEGORY', 'WHITESPACE', 'Cbb', 'Neu', 'Nf', 'Nc', 'Caa', 'Nes', 'Nc', 'Na', 'Nc', 'D', 'VC', 'Neu', 'Caa', 'Neu', 'Nf', 'Na', 'COMMACATEGORY', 'Na', 'VH', 'PERIODCATEGORY', 'WHITESPACE', 'Neu', 'Nd', 'Na', 'VC', 'Na', 'P', 'Nd', 'Nd', 'Nd', 'VE', 'COMMACATEGORY', 'VC', 'Nh', 'D', 'VCL', 'Nc', 'Na', 'Nv', 'Na', 'Nc', 'VD', 'Nv', 'Na', 'Caa', 'Na', 'COMMACATEGORY', 'Caa', 'VH', 'VA', 'Nc', 'Na', 'Nb', 'Nc', 'PAUSECATEGORY', 'Nc', 'Caa', 'Na', 'VC', 'Nc', 'VE', 'VC', 'VH', 'Na', 'COMMACATEGORY', 'P', 'Na', 'Ng', 'VC', 'VA', 'COMMACATEGORY', 'Cbb', 'D', 'VE', 'Na', 'COMMACATEGORY', 'Nes', 'Na', 'D', 'VC', 'Na', 'Na', 'COMMACATEGORY', 'VA', 'Nh', 'VF', 'VK', 'D', 'P', 'A', 'Na', 'VA', 'Cbb', 'VA', 'VH', 'VH', 'PERIODCATEGORY', 'WHITESPACE', 'P', 'VC', 'VA', 'Na', 'COMMACATEGORY', 'Nes', 'Nd', 'Nv', 'Na', 'P', 'P', 'Nc', 'Neu', 'Nc', 'VC', 'Ng', 'COMMACATEGORY', 'Cbb', 'D', 'P', 'Nc', 'FW', 'Na', 'Na', 'VH', 'D', 'COMMACATEGORY', 'VF', 'Nh', 'D', 'VC', 'PERIODCATEGORY', 'WHITESPACE', 'VE', 'Na', 'COLONCATEGORY', 'FW', 'Neu', 'Caa', 'FW', 'WHITESPACE', 'WHITESPACE', 'Nc', 'Na', 'Nb', 'Nf', 'VH', 'Nc', 'PARENTHESISCATEGORY', 'Na', 'COLONCATEGORY', 'WHITESPACE', 'PARENTHESISCATEGORY', 'WHITESPACE', 'WHITESPACE', 'Nc', 'Na', 'Nc', 'Nc', 'PARENTHESISCATEGORY', 'Na', 'COLONCATEGORY', 'WHITESPACE', 'PARENTHESISCATEGORY', 'WHITESPACE', 'WHITESPACE', 'Nc', 'Na', 'Nc', 'Na', 'VC', 'Nc', 'PARENTHESISCATEGORY', 'Na', 'COLONCATEGORY', 'WHITESPACE', 'PARENTHESISCATEGORY']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Convert-stopwords-in-spaCy-from-simplified-to-Taiwanese-traditional">
<a class="anchor" href="#Convert-stopwords-in-spaCy-from-simplified-to-Taiwanese-traditional" aria-hidden="true"><span class="octicon octicon-link"></span></a>Convert stopwords in <code>spaCy</code> from simplified to Taiwanese traditional<a class="anchor-link" href="#Convert-stopwords-in-spaCy-from-simplified-to-Taiwanese-traditional"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>spaCy comes with a built-in set of stopwords (basically words that we'd like to ignore), accessible via <code>spacy.lang.zh.stop_words</code>. To make good use of it, let's convert all the words from simplified characters to traditional ones with the help of <code>OpenCC</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install OpenCC
<span class="kn">import</span> <span class="nn">opencc</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>OpenCC</code> does not just convert characters mechanically. It has the ability to convert words from simplified characters to their equivalent phrasing in Taiwan Mandarin, which is done by <code>s2twp.json</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">spacy.lang.zh.stop_words</span> <span class="kn">import</span> <span class="n">STOP_WORDS</span>
<span class="n">converter</span> <span class="o">=</span> <span class="n">opencc</span><span class="o">.</span><span class="n">OpenCC</span><span class="p">(</span><span class="s1">'s2twp.json'</span><span class="p">)</span>
<span class="n">spacy_stopwords_sim</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">STOP_WORDS</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">spacy_stopwords_sim</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="n">spacy_stopwords_tra</span> <span class="o">=</span> <span class="p">[</span><span class="n">converter</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">spacy_stopwords_sim</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">spacy_stopwords_tra</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>['因为', '奇', '嘿嘿', '其次', '偏偏']
['因為', '奇', '嘿嘿', '其次', '偏偏']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Define-a-class-for-implementing-TextRank">
<a class="anchor" href="#Define-a-class-for-implementing-TextRank" aria-hidden="true"><span class="octicon octicon-link"></span></a>Define a class for implementing TextRank<a class="anchor-link" href="#Define-a-class-for-implementing-TextRank"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you're dealing with English texts, you can implement TextRank quite easily with <code>textaCy</code>, the tagline of which is <code>NLP, before and after spaCy</code>. But I couldn't get it to work for Chinese texts, so I had to implement TextRank from scratch. Luckily, I got a jump-start from this <a href="https://gist.github.com/BrambleXu/3d47bbdbd1ee4e6fc695b0ddb88cbf99">gist</a>, which offers a blueprint for the following definitions.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">TextRank4Keyword</span><span class="p">():</span>
    <span class="sd">"""Extract keywords from text"""</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="mf">0.85</span> <span class="c1"># damping coefficient, usually is .85</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_diff</span> <span class="o">=</span> <span class="mf">1e-5</span> <span class="c1"># convergence threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># iteration steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_weight</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># save keywords and its weight</span>

    <span class="k">def</span> <span class="nf">set_stopwords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">custom_stopwords</span><span class="p">):</span>  
        <span class="sd">"""Set stop words"""</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">spacy_stopwords_tra</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">custom_stopwords</span><span class="p">)):</span>
            <span class="n">lexeme</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
            <span class="n">lexeme</span><span class="o">.</span><span class="n">is_stop</span> <span class="o">=</span> <span class="kc">True</span>
    
    <span class="k">def</span> <span class="nf">sentence_segment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">doc</span><span class="p">,</span> <span class="n">candidate_pos</span><span class="p">,</span> <span class="n">lower</span><span class="p">):</span>
        <span class="sd">"""Store those words only in cadidate_pos"""</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">sents</span><span class="p">:</span>
            <span class="n">selected_words</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">sent</span><span class="p">:</span>
                <span class="c1"># Store words only with cadidate POS tag</span>
                <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">pos_</span> <span class="ow">in</span> <span class="n">candidate_pos</span> <span class="ow">and</span> <span class="n">token</span><span class="o">.</span><span class="n">is_stop</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">lower</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="n">selected_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">selected_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
            <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">selected_words</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sentences</span>
        
    <span class="k">def</span> <span class="nf">get_vocab</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentences</span><span class="p">):</span>
        <span class="sd">"""Get all tokens"""</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
                    <span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">vocab</span>
    
    <span class="k">def</span> <span class="nf">get_token_pairs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">sentences</span><span class="p">):</span>
        <span class="sd">"""Build token_pairs from windows in sentences"""</span>
        <span class="n">token_pairs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="n">window_size</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">j</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
                        <span class="k">break</span>
                    <span class="n">pair</span> <span class="o">=</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">sentence</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                    <span class="k">if</span> <span class="n">pair</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">token_pairs</span><span class="p">:</span>
                        <span class="n">token_pairs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pair</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">token_pairs</span>
        
    <span class="k">def</span> <span class="nf">symmetrize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">a</span><span class="o">.</span><span class="n">T</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">diagonal</span><span class="p">())</span>
    
    <span class="k">def</span> <span class="nf">get_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">token_pairs</span><span class="p">):</span>
        <span class="sd">"""Get normalized matrix"""</span>
        <span class="c1"># Build matrix</span>
        <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">'float'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">word1</span><span class="p">,</span> <span class="n">word2</span> <span class="ow">in</span> <span class="n">token_pairs</span><span class="p">:</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">word1</span><span class="p">],</span> <span class="n">vocab</span><span class="p">[</span><span class="n">word2</span><span class="p">]</span>
            <span class="n">g</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            
        <span class="c1"># Get Symmeric matrix</span>
        <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">symmetrize</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
        
        <span class="c1"># Normalize matrix by column</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">g_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">norm</span><span class="o">!=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># this is to ignore the 0 element in norm</span>
        
        <span class="k">return</span> <span class="n">g_norm</span>
    
    <span class="c1"># I revised this function to return keywords as a list</span>
    <span class="k">def</span> <span class="nf">get_keywords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="sd">"""Print top number keywords"""</span>
        <span class="n">node_weight</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_weight</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node_weight</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">keywords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">number</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="k">return</span> <span class="n">keywords</span>

    <span class="k">def</span> <span class="nf">analyze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> 
                <span class="n">candidate_pos</span><span class="o">=</span><span class="p">[</span><span class="s1">'NOUN'</span><span class="p">,</span> <span class="s1">'VERB'</span><span class="p">],</span> 
                <span class="n">window_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">stopwords</span><span class="o">=</span><span class="nb">list</span><span class="p">()):</span>
        <span class="sd">"""Main function to analyze text"""</span>
        
        <span class="c1"># Set stop words</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_stopwords</span><span class="p">(</span><span class="n">stopwords</span><span class="p">)</span>

        <span class="c1"># Pare text with spaCy</span>
        <span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">token_str</span><span class="p">)</span>
        
        <span class="c1"># Filter sentences</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sentence_segment</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">candidate_pos</span><span class="p">,</span> <span class="n">lower</span><span class="p">)</span> <span class="c1"># list of list of words</span>
        
        <span class="c1"># Build vocabulary</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
        
        <span class="c1"># Get token_pairs from windows</span>
        <span class="n">token_pairs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_token_pairs</span><span class="p">(</span><span class="n">window_size</span><span class="p">,</span> <span class="n">sentences</span><span class="p">)</span>
        
        <span class="c1"># Get normalized matrix</span>
        <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_matrix</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">token_pairs</span><span class="p">)</span>
        
        <span class="c1"># Initionlization for weight(pagerank value)</span>
        <span class="n">pr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
        
        <span class="c1"># Iteration</span>
        <span class="n">previous_pr</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">):</span>
            <span class="n">pr</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">pr</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">previous_pr</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">pr</span><span class="p">))</span>  <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_diff</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">previous_pr</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">pr</span><span class="p">)</span>

        <span class="c1"># Get weight for each node</span>
        <span class="n">node_weight</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">node_weight</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">pr</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">node_weight</span> <span class="o">=</span> <span class="n">node_weight</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can create an instace of the <code>TextRank4Keyword</code> class and call the <code>set_stopwords</code> function with our <code>CUSTOM_STOPWORDS</code> variable. This created a set of stopwords resulting from the union of both our custom stopwords and spaCy's built-in stopwords. And only words that meet these two criteria would become candidates for keywords:</p>
<ul>
<li>they are <strong>not</strong> in the set of stopwords; </li>
<li>their POS labels are one of those listed in <code>candidate_pos</code>, which includes <code>NOUN</code> and <code>VERB</code> by default. </li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tr4w</span> <span class="o">=</span> <span class="n">TextRank4Keyword</span><span class="p">()</span>
<span class="n">tr4w</span><span class="o">.</span><span class="n">set_stopwords</span><span class="p">(</span><span class="n">CUSTOM_STOPWORDS</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Put-it-together">
<a class="anchor" href="#Put-it-together" aria-hidden="true"><span class="octicon octicon-link"></span></a>Put it together<a class="anchor-link" href="#Put-it-together"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's put it all together by defining a main function for keyword extraction.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">extract_keys_from_str</span><span class="p">(</span><span class="n">raw_text</span><span class="p">):</span>
  <span class="n">text</span> <span class="o">=</span> <span class="n">clean_all</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span> <span class="c1">#clean the raw text</span>
  <span class="n">ws</span>  <span class="o">=</span> <span class="n">ws_driver</span><span class="p">([</span><span class="n">text</span><span class="p">])</span> <span class="c1">#tokenize the text with CKIP Transformers</span>
  <span class="n">tokenized_text</span> <span class="o">=</span> <span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ws</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1">#join a list into a string </span>
  <span class="n">tr4w</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="n">tokenized_text</span><span class="p">)</span> <span class="c1">#create a spaCy Doc object with the string and calculate weights for words</span>
  <span class="n">keys</span> <span class="o">=</span> <span class="n">tr4w</span><span class="o">.</span><span class="n">get_keywords</span><span class="p">(</span><span class="n">KW_NUM</span><span class="p">)</span> <span class="c1">#get top 10 keywords, as set by the KW_NUM variable</span>
  <span class="k">return</span> <span class="n">keys</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here're the top ten keywords for our sample text. The results are quite satisfactory.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">keys</span> <span class="o">=</span> <span class="n">extract_keys_from_str</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keys</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">keys</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Tokenization: 100%|██████████| 1/1 [00:00&lt;00:00, 221.73it/s]
Inference: 100%|██████████| 1/1 [00:05&lt;00:00,  5.20s/it]
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>['土地', '公園', '地政局', '文化', '推出', '面積', '標售', '道路', '優質', '投標']</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As a comparison, here're the top 10 keywords produced by Jieba's implementation of TextRank, 7 of which are identical to the list above. Although extracting keywords with Jieba is quick and easy, it tends to give rise to wrongly segmented tokens, such as <code>政局</code> in this example, which should have been <code>地政局</code> for Land Administration Bureau.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">jieba.analyse</span> <span class="k">as</span> <span class="nn">KE</span>
<span class="n">jieba_kw</span> <span class="o">=</span> <span class="n">KE</span><span class="o">.</span><span class="n">textrank</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">topK</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">jieba_kw</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>['土地', '政局', '投標', '公園', '投資', '標售', '文化', '開發', '優質', '推出']</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Other-libraries-that-failed">
<a class="anchor" href="#Other-libraries-that-failed" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other libraries that failed<a class="anchor-link" href="#Other-libraries-that-failed"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="textaCy">
<a class="anchor" href="#textaCy" aria-hidden="true"><span class="octicon octicon-link"></span></a><code>textaCy</code><a class="anchor-link" href="#textaCy"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install textacy
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With textaCy, you can load a spaCy language model and then create a spaCy <code>Doc</code> object using that model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">textacy</span>
<span class="n">zh</span> <span class="o">=</span> <span class="n">textacy</span><span class="o">.</span><span class="n">load_spacy_lang</span><span class="p">(</span><span class="s2">"zh_core_web_sm"</span><span class="p">)</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">textacy</span><span class="o">.</span><span class="n">make_spacy_doc</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="n">zh</span><span class="p">)</span>
<span class="n">doc</span><span class="o">.</span><span class="n">_</span><span class="o">.</span><span class="n">preview</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'Doc(612 tokens: "市府地政局109年度第4季開發區土地標售，共計推出8標9筆優質建地，訂於109年12月16日開...")'</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>textaCy implements four algorithms for keyword extraction, including TextRank. But I got useless results by calling the  <code>textacy.ke.textrank</code> function with <code>doc</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">textacy.ke</span> <span class="k">as</span> <span class="nn">ke</span>
<span class="n">ke</span><span class="o">.</span><span class="n">textrank</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('     ', 6.0)]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="pyate">
<a class="anchor" href="#pyate" aria-hidden="true"><span class="octicon octicon-link"></span></a><code>pyate</code><a class="anchor-link" href="#pyate"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install pyate
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>pyate</code> has a built-in <code>TermExtractionPipeline</code> class for extracting keywords, which can be added to spaCy's pipeline. But it didn't work and this error message showed up: <code>TypeError: load() got an unexpected keyword argument 'parser'</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pyate.term_extraction_pipeline</span> <span class="kn">import</span> <span class="n">TermExtractionPipeline</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="n">TermExtractionPipeline</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">TypeError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-27-f5a8398fbc3b&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg">#collapse-output</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">from</span> pyate<span class="ansi-blue-fg">.</span>term_extraction_pipeline <span class="ansi-green-fg">import</span> TermExtractionPipeline
<span class="ansi-green-intense-fg ansi-bold">      3</span> nlp<span class="ansi-blue-fg">.</span>add_pipe<span class="ansi-blue-fg">(</span>TermExtractionPipeline<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/pyate/__init__.py</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">from</span> <span class="ansi-blue-fg">.</span>term_extraction <span class="ansi-green-fg">import</span> TermExtraction<span class="ansi-blue-fg">,</span> add_term_extraction_method
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">from</span> <span class="ansi-blue-fg">.</span>basic <span class="ansi-green-fg">import</span> basic
<span class="ansi-green-intense-fg ansi-bold">      3</span> <span class="ansi-green-fg">from</span> <span class="ansi-blue-fg">.</span>combo_basic <span class="ansi-green-fg">import</span> combo_basic
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-green-fg">from</span> <span class="ansi-blue-fg">.</span>cvalues <span class="ansi-green-fg">import</span> cvalues
<span class="ansi-green-intense-fg ansi-bold">      5</span> <span class="ansi-green-fg">from</span> <span class="ansi-blue-fg">.</span>term_extractor <span class="ansi-green-fg">import</span> term_extractor

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/pyate/term_extraction.py</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     20</span> 
<span class="ansi-green-intense-fg ansi-bold">     21</span> 
<span class="ansi-green-fg">---&gt; 22</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">class</span> TermExtraction<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     23</span>     <span class="ansi-red-fg"># TODO: find some way to prevent redundant loading of csv files</span>
<span class="ansi-green-intense-fg ansi-bold">     24</span>     nlp <span class="ansi-blue-fg">=</span> spacy<span class="ansi-blue-fg">.</span>load<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"en_core_web_sm"</span><span class="ansi-blue-fg">,</span> parser<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span> entity<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/pyate/term_extraction.py</span> in <span class="ansi-cyan-fg">TermExtraction</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     22</span> <span class="ansi-green-fg">class</span> TermExtraction<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     23</span>     <span class="ansi-red-fg"># TODO: find some way to prevent redundant loading of csv files</span>
<span class="ansi-green-fg">---&gt; 24</span><span class="ansi-red-fg">     </span>nlp <span class="ansi-blue-fg">=</span> spacy<span class="ansi-blue-fg">.</span>load<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"en_core_web_sm"</span><span class="ansi-blue-fg">,</span> parser<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span> entity<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span>     matcher <span class="ansi-blue-fg">=</span> Matcher<span class="ansi-blue-fg">(</span>nlp<span class="ansi-blue-fg">.</span>vocab<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span>     language <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">"en"</span>

<span class="ansi-red-fg">TypeError</span>: load() got an unexpected keyword argument 'parser'</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I found on the documentation page that <code>pyate</code> only supports English and Italian, which may account for the error I got.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="pytextrank">
<a class="anchor" href="#pytextrank" aria-hidden="true"><span class="octicon octicon-link"></span></a><code>pytextrank</code><a class="anchor-link" href="#pytextrank"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install pytextrank
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To add TextRank to the spaCy pipeline, I followed the <a href="https://spacy.io/universe/project/spacy-pytextrank">instructions</a> found on spaCy's documentation. But an error popped up. Luckily, <code>ValueError</code> offers possible ways to fix the problem.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pytextrank</span>
<span class="n">tr</span> <span class="o">=</span> <span class="n">pytextrank</span><span class="o">.</span><span class="n">TextRank</span><span class="p">()</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="n">tr</span><span class="o">.</span><span class="n">PipelineComponent</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'textrank'</span><span class="p">,</span> <span class="n">last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-29-cd319957f3b6&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> <span class="ansi-green-fg">import</span> pytextrank
<span class="ansi-green-intense-fg ansi-bold">      3</span> tr <span class="ansi-blue-fg">=</span> pytextrank<span class="ansi-blue-fg">.</span>TextRank<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 4</span><span class="ansi-red-fg"> </span>nlp<span class="ansi-blue-fg">.</span>add_pipe<span class="ansi-blue-fg">(</span>tr<span class="ansi-blue-fg">.</span>PipelineComponent<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">'textrank'</span><span class="ansi-blue-fg">,</span> last<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/spacy/language.py</span> in <span class="ansi-cyan-fg">add_pipe</span><span class="ansi-blue-fg">(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)</span>
<span class="ansi-green-intense-fg ansi-bold">    746</span>         batch_size<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1000</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    747</span>         disable<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 748</span><span class="ansi-red-fg">         </span>cleanup<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    749</span>         component_cfg<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    750</span>         n_process<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span>

<span class="ansi-red-fg">ValueError</span>: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got &lt;bound method TextRank.PipelineComponent of &lt;pytextrank.pytextrank.TextRank object at 0x7f4fea403550&gt;&gt; (name: 'textrank').

- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.

- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.

- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So I used the <code>@Language.factory</code> decorator to define a TextRank component, and then called the <code>nlp.add_pipe</code> function with <code>textrank</code>. But this didn't work either. The error message reads: <code>'Chinese' object has no attribute 'sents'</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">spacy.language</span> <span class="kn">import</span> <span class="n">Language</span>

<span class="n">tr</span> <span class="o">=</span> <span class="n">pytextrank</span><span class="o">.</span><span class="n">TextRank</span><span class="p">()</span>

<span class="nd">@Language</span><span class="o">.</span><span class="n">factory</span><span class="p">(</span><span class="s2">"textrank"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">create_textrank_component</span><span class="p">(</span><span class="n">nlp</span><span class="p">:</span> <span class="n">Language</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tr</span><span class="o">.</span><span class="n">PipelineComponent</span><span class="p">(</span><span class="n">nlp</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="s1">'textrank'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-31-1c84bbe50472&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg">#collapse-output</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>nlp<span class="ansi-blue-fg">.</span>add_pipe<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">'textrank'</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/spacy/language.py</span> in <span class="ansi-cyan-fg">add_pipe</span><span class="ansi-blue-fg">(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)</span>
<span class="ansi-green-intense-fg ansi-bold">    770</span>         <span class="ansi-green-fg">if</span> is_python2 <span class="ansi-green-fg">and</span> n_process <span class="ansi-blue-fg">!=</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    771</span>             warnings<span class="ansi-blue-fg">.</span>warn<span class="ansi-blue-fg">(</span>Warnings<span class="ansi-blue-fg">.</span>W023<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 772</span><span class="ansi-red-fg">             </span>n_process <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">    773</span>         <span class="ansi-green-fg">if</span> n_threads <span class="ansi-blue-fg">!=</span> <span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    774</span>             warnings<span class="ansi-blue-fg">.</span>warn<span class="ansi-blue-fg">(</span>Warnings<span class="ansi-blue-fg">.</span>W016<span class="ansi-blue-fg">,</span> DeprecationWarning<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/spacy/language.py</span> in <span class="ansi-cyan-fg">create_pipe</span><span class="ansi-blue-fg">(self, factory_name, name, config, raw_config, validate)</span>
<span class="ansi-green-intense-fg ansi-bold">    656</span>         link_vectors_to_models<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>vocab<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    657</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>vocab<span class="ansi-blue-fg">.</span>vectors<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 658</span><span class="ansi-red-fg">             </span>cfg<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">"pretrained_vectors"</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>vocab<span class="ansi-blue-fg">.</span>vectors<span class="ansi-blue-fg">.</span>name
<span class="ansi-green-intense-fg ansi-bold">    659</span>         <span class="ansi-green-fg">if</span> sgd <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    660</span>             sgd <span class="ansi-blue-fg">=</span> create_default_optimizer<span class="ansi-blue-fg">(</span>Model<span class="ansi-blue-fg">.</span>ops<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/thinc/config.py</span> in <span class="ansi-cyan-fg">resolve</span><span class="ansi-blue-fg">(cls, config, schema, overrides, validate)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/thinc/config.py</span> in <span class="ansi-cyan-fg">_make</span><span class="ansi-blue-fg">(cls, config, schema, overrides, resolve, validate)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/thinc/config.py</span> in <span class="ansi-cyan-fg">_fill</span><span class="ansi-blue-fg">(cls, config, schema, validate, resolve, parent, overrides)</span>

<span class="ansi-green-fg">&lt;ipython-input-30-fb02aff6bab9&gt;</span> in <span class="ansi-cyan-fg">create_textrank_component</span><span class="ansi-blue-fg">(nlp, name)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> <span class="ansi-blue-fg">@</span>Language<span class="ansi-blue-fg">.</span>factory<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"textrank"</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      6</span> <span class="ansi-green-fg">def</span> create_textrank_component<span class="ansi-blue-fg">(</span>nlp<span class="ansi-blue-fg">:</span> Language<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">:</span> str<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">----&gt; 7</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> tr<span class="ansi-blue-fg">.</span>PipelineComponent<span class="ansi-blue-fg">(</span>nlp<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/pytextrank/pytextrank.py</span> in <span class="ansi-cyan-fg">PipelineComponent</span><span class="ansi-blue-fg">(self, doc)</span>
<span class="ansi-green-intense-fg ansi-bold">    559</span>         Doc<span class="ansi-blue-fg">.</span>set_extension<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"phrases"</span><span class="ansi-blue-fg">,</span> force<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span> default<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    560</span>         Doc<span class="ansi-blue-fg">.</span>set_extension<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"textrank"</span><span class="ansi-blue-fg">,</span> force<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span> default<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 561</span><span class="ansi-red-fg">         </span>doc<span class="ansi-blue-fg">.</span>_<span class="ansi-blue-fg">.</span>phrases <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>calc_textrank<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    562</span> 
<span class="ansi-green-intense-fg ansi-bold">    563</span>         <span class="ansi-green-fg">return</span> doc

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/pytextrank/pytextrank.py</span> in <span class="ansi-cyan-fg">calc_textrank</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    375</span>         t0 <span class="ansi-blue-fg">=</span> time<span class="ansi-blue-fg">.</span>time<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    376</span> 
<span class="ansi-green-fg">--&gt; 377</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">for</span> sent <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>doc<span class="ansi-blue-fg">.</span>sents<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    378</span>             self<span class="ansi-blue-fg">.</span>link_sentence<span class="ansi-blue-fg">(</span>sent<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    379</span> 

<span class="ansi-red-fg">AttributeError</span>: 'Chinese' object has no attribute 'sents'</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="rake-spacy">
<a class="anchor" href="#rake-spacy" aria-hidden="true"><span class="octicon octicon-link"></span></a><code>rake-spacy</code><a class="anchor-link" href="#rake-spacy"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I couldn't even install <code>rake-spacy</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install rake-spacy
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-red-fg">ERROR: Could not find a version that satisfies the requirement rake-spacy</span>
<span class="ansi-red-fg">ERROR: No matching distribution found for rake-spacy</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="rake-keyword">
<a class="anchor" href="#rake-keyword" aria-hidden="true"><span class="octicon octicon-link"></span></a><code>rake-keyword</code><a class="anchor-link" href="#rake-keyword"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install rake-keyword
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>According to the <a href="https://pypi.org/project/rake-keyword/">documentation on PYPI</a>, the import is done by <code>from rake import Rake</code>, but it didn't work.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">rake</span> <span class="kn">import</span> <span class="n">Rake</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ImportError</span>                               Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-34-fe043f886018&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg">#collapse-output</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">from</span> rake <span class="ansi-green-fg">import</span> Rake

<span class="ansi-red-fg">ImportError</span>: cannot import name 'Rake'

<span class="ansi-red-fg">---------------------------------------------------------------------------</span><span class="ansi-green-fg">
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
"Open Examples" button below.
</span><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>However, based on the <a href="https://github.com/u-prashant/RAKE">documentation on GitHub</a>, this is done by <code>from rake import RAKE</code> instead. But it didn't work either.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">rake</span> <span class="kn">import</span> <span class="n">RAKE</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Output" data-close="Show Output"></summary>
        <p>
</p>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ImportError</span>                               Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-35-59e63adf01ef&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg">#collapse-output</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">from</span> rake <span class="ansi-green-fg">import</span> RAKE

<span class="ansi-red-fg">ImportError</span>: cannot import name 'RAKE'

<span class="ansi-red-fg">---------------------------------------------------------------------------</span><span class="ansi-green-fg">
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
"Open Examples" button below.
</span><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
</pre>
</div>
</div>

</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Recap">
<a class="anchor" href="#Recap" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recap<a class="anchor-link" href="#Recap"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Integration of CKIP Transformers with spaCy and the TextRank algorithm generates decent results for extracting keywords from texts in traditional Chinese. Although there are many Python libraries out there that implement TextRank, none of them works better than the  <code>TextRank4Keyword</code> class crafted from scratch. Until I figure out how to properly add the TextRank component to the spaCy pipeline, I'll stick with my working pipeline shown here. As a final thought, spaCy recently released v3.0, which supports pretrained transformer models. I can't wait to give it a try and see how this would change the workflow of extracting keywords or other NLP tasks. But that'll have to wait until next post.</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/blog.ai/keyword-extraction/spacy/textacy/ckip-transformers/jieba/textrank/rake/2021/02/16/Adding-a-custom-tokenizer-to-spaCy-and-extracting-keywords.html" hidden></a>
</article>

<script src="https://utteranc.es/client.js"
        repo="howard-haowen/blog.ai"
        issue-term="[ENTER TERM HERE]"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog.ai/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog.ai/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog.ai/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>AI through a linguist&#39;s looking glass</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/howard-haowen" title="howard-haowen"><svg class="svg-icon grey"><use xlink:href="/blog.ai/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/haowen-jiang-phd-16242074" title="haowen-jiang-phd-16242074"><svg class="svg-icon grey"><use xlink:href="/blog.ai/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
