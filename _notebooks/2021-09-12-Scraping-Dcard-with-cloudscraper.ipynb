{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-09-12-Scraping-Dcard-with-cloudscraper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1uj1lhd6lBCaubDjiY7yMopC8R_s2vpMM",
      "authorship_tag": "ABX9TyNtbL107Oq05ivdJwRSkGbs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_XC0s-awQM5"
      },
      "source": [
        "# Scraping Dcard with cloudscraper\n",
        "> This post goes over the steps for scraping data from Dcard at regular intervals and saving the data to a SQL database. \n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- categories: [cloudscraper, schedule, sqlite3, logging]\n",
        "- image: images/data-scraping.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGghH0UKs12W"
      },
      "source": [
        "![](https://github.com/howard-haowen/blog.ai/raw/master/images/data-scraping.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa-Y5ndYUtWF"
      },
      "source": [
        "# Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDdxg8hnLXbT"
      },
      "source": [
        "`Dcard` is a popular social networking platform in Taiwan, and as such offers great resources for text mining and NLP model building. Our goals in this post is to scrape data from Dcard at regular intervals and persist it to a SQL database without duplicating the same records. We'll be leveraging the Dcard API v2 as well as the following libraries, which are not included in [Python's standard library](https://docs.python.org/3/library/):\n",
        "- [`cloudscraper`](https://pypi.org/project/cloudscraper/): for bypassing Cloudflare's anti-bot page\n",
        "- [`pandas`](https://pypi.org/project/pandas/): for organizing the scraped data into a tabular format, which can then be easily saved as a SQL table\n",
        "- [`schedule`](https://pypi.org/project/schedule/): for scheduling tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg2cRuRCAW-_"
      },
      "source": [
        "# Installing dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTuQ16omAm1u"
      },
      "source": [
        "Since `pandas` is preinstalled on Colab, we only need to install `cloudscraper` and `schedule`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQXT-fJ9DZiP",
        "outputId": "36d89614-3c23-4f99-87a9-93c3b0a93d3c"
      },
      "source": [
        "#collapse_output\n",
        "!pip install cloudscraper\n",
        "!pip install schedule\n",
        "#!pip pandas # uncomment this if pandas is not installed in your environment"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cloudscraper\n",
            "  Downloading cloudscraper-1.2.58-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 30 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 40 kB 37.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 61 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 71 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 81 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 92 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 96 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.9.2 in /usr/local/lib/python3.7/dist-packages (from cloudscraper) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.7/dist-packages (from cloudscraper) (2.4.7)\n",
            "Collecting requests-toolbelt>=0.9.1\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 20 kB 36.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 30 kB 43.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 40 kB 49.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 51 kB 54.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 54 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.2->cloudscraper) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.2->cloudscraper) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.2->cloudscraper) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.2->cloudscraper) (1.24.3)\n",
            "Installing collected packages: requests-toolbelt, cloudscraper\n",
            "Successfully installed cloudscraper-1.2.58 requests-toolbelt-0.9.1\n",
            "Collecting schedule\n",
            "  Downloading schedule-1.1.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfAQyTtIBRF5"
      },
      "source": [
        "Let's check out the Python version on Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGWUaXL7DKNs",
        "outputId": "1a0d41c0-7b83-4f54-ab7a-4bb53f44e557"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE05O6PhediD"
      },
      "source": [
        "# Testing the Dcard API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3S_JSAWC5WU"
      },
      "source": [
        "Let's first test the Dcard API v2 with `cloudscraper`, the syntax of which is much like that of `requests`. The only difference is that we'll have to first create a scraper instance with `cloudscraper.create_scraper()`. For each HTTP request, we'll get a batch of 30 posts. The `forum` variable in the URL is the English name of a forum, and we'll first test the one named `stock`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8aGorvfninP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8587ffaf-9441-4dea-f82c-52b5be3b124c"
      },
      "source": [
        "import cloudscraper\n",
        "\n",
        "forum = \"stock\"\n",
        "URL = f\"https://www.dcard.tw/service/api/v2/forums/{forum}/posts\"\n",
        "scraper = cloudscraper.create_scraper() \n",
        "batch = scraper.get(URL).json()\n",
        "len(batch)  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q_MHm-s-YgP"
      },
      "source": [
        "Here's what one single post looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5tH2gJLCMub",
        "outputId": "0335f28d-0b22-4189-cdd5-c0fac217f3a6"
      },
      "source": [
        "#collapse_output\n",
        "import pprint\n",
        "pprint.pprint(batch[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'activityAvatar': '',\n",
            " 'anonymousDepartment': True,\n",
            " 'anonymousSchool': False,\n",
            " 'categories': ['請益'],\n",
            " 'commentCount': 0,\n",
            " 'createdAt': '2021-09-12T14:22:22.276Z',\n",
            " 'customStyle': None,\n",
            " 'elapsedTime': 515,\n",
            " 'excerpt': '如題，我知道官股存股首推兆豐金，配息又配股，可是會配股的股票代表股本要很大，且每年獲利如果沒跟上的話，EPS會掉，股價也會跟著掉，官股獲利跟十年前比有如一攤死水，小弟我真的不曉得為什麼存股比起存民營金',\n",
            " 'excerptComments': [],\n",
            " 'forumAlias': 'stock',\n",
            " 'forumId': '2fb88b62-aa28-4b18-af51-dda08dd037a9',\n",
            " 'forumName': '股票',\n",
            " 'gender': 'M',\n",
            " 'hidden': False,\n",
            " 'id': 236953704,\n",
            " 'isModerator': False,\n",
            " 'isSuspiciousAccount': False,\n",
            " 'layout': 'classic',\n",
            " 'likeCount': 0,\n",
            " 'media': [],\n",
            " 'mediaMeta': [],\n",
            " 'memberType': '',\n",
            " 'meta': {'layout': 'classic'},\n",
            " 'nsfw': False,\n",
            " 'pinned': False,\n",
            " 'postAvatar': '',\n",
            " 'reactions': [],\n",
            " 'replyId': None,\n",
            " 'replyTitle': None,\n",
            " 'reportReason': '',\n",
            " 'reportReasonText': '',\n",
            " 'school': '弘光科技大學',\n",
            " 'spoilerAlert': False,\n",
            " 'tags': [],\n",
            " 'title': '#請益 #請益 金融股存股疑問 官股 民股',\n",
            " 'topics': ['請益', '金融', '投資', '官股', '民營金控'],\n",
            " 'totalCommentCount': 0,\n",
            " 'updatedAt': '2021-09-12T14:22:22.276Z',\n",
            " 'verifiedBadge': False,\n",
            " 'withImages': False,\n",
            " 'withNickname': False,\n",
            " 'withVideos': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5wvebUmfK3-"
      },
      "source": [
        "# Parsing the JSON response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1iXp0UT-t8L"
      },
      "source": [
        "Then we'll parse the JSON response to get the data we're interested in, including `title`, `createdAt`, `categories`, `excerpt`, and `topics`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q0-hsKhFDgP"
      },
      "source": [
        "cols = ['title', 'createdAt', 'categories', 'excerpt', 'topics']\n",
        "title = [item.get(cols[0]) for item in batch]\n",
        "createdAt = [item.get(cols[1]) for item in batch]\n",
        "categories = [item.get(cols[2]) for item in batch]\n",
        "excerpt = [item.get(cols[3]) for item in batch]\n",
        "topics = [item.get(cols[4]) for item in batch]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLQWtJUO4i7X"
      },
      "source": [
        "For instance, the `topics` column contains a list of topic terms for each post, but the list may be empty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5etQ72sbJeHl",
        "outputId": "2e7bb8e6-a80d-4055-d578-a388055d3a15"
      },
      "source": [
        "#collapse_output\n",
        "topics"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['請益', '金融', '投資', '官股', '民營金控'],\n",
              " ['分析', '台股', '當沖', '波段', '技術分析'],\n",
              " ['投資', '股票', '理財', '台股', '股市'],\n",
              " ['請益'],\n",
              " ['兇', '韭菜'],\n",
              " ['投資', '股票', '美股', 'ETF', '新聞'],\n",
              " ['投資', '股票', '美股', '股市', '新手'],\n",
              " ['股票', '投資', '理財', '台股', '當沖'],\n",
              " ['投資', '股票', '理財', '台股', '生活'],\n",
              " ['股票', '美股', '技術分析', '狼王'],\n",
              " ['請益', '新聞', '影響', '投資', '股票'],\n",
              " ['投資', '股票', '理財', '台股', '股市'],\n",
              " ['時事', '分享', '股票', '理財', '新聞'],\n",
              " ['老師', '直播', '筆記', '股票', '投資'],\n",
              " ['海外', '券商', '法律'],\n",
              " ['分享', '金融', '投資', '股票', '理財'],\n",
              " ['投資', 'app'],\n",
              " ['股票'],\n",
              " ['股票', '分享'],\n",
              " ['分享', '股票', '投資', '當沖', '分析'],\n",
              " ['股息', '分享', '股利', '股票', '投資'],\n",
              " ['投資', '理財', '台股', '股票', '股市'],\n",
              " ['股票', '台股'],\n",
              " ['投資', '股票', '理財', '台股', '股市'],\n",
              " ['股市', '當沖', '波段', '大盤'],\n",
              " ['etf', '投資'],\n",
              " ['美股', '股票', '技術分析', '狼王'],\n",
              " ['美股', '股票', '理財', 'NVIDIA', '投資'],\n",
              " ['股票', '投資'],\n",
              " ['請益', '券商', '股票', '投資', '台股']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TofBuDEBgSvH"
      },
      "source": [
        "# Creating DataFrame from JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfl0zdRcEnZ3"
      },
      "source": [
        "Now let's define a function called `parse_batch()` that takes the JSON response as input and returns a DataFrame instance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5b9TAAJJOn7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def parse_batch(batch):\n",
        "    createdAt = [item.get('createdAt', 'None') for item in batch]\n",
        "    title = [item.get('title', 'None') for item in batch]\n",
        "    excerpt = [item.get('excerpt', 'None') for item in batch]\n",
        "    dummy = []\n",
        "    categories = [item.get('categories', dummy) for item in batch] # every element is a list\n",
        "    topics = [item.get('topics', dummy) for item in batch] # every element is a list\n",
        "    data = {\n",
        "        'createdAt': createdAt,\n",
        "        'title': title,\n",
        "        'excerpt': excerpt,\n",
        "        'categories': categories,\n",
        "        'topics': topics,    \n",
        "        }\n",
        "    df = pd.DataFrame(data)\n",
        "    df.loc [:, 'categories'] = df['categories'].apply(lambda x: \" | \".join(x))\n",
        "    df.loc [:, 'topics'] = df['topics'].apply(lambda x: \" | \".join(x))\n",
        "    return df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUWc6pzqFWNN"
      },
      "source": [
        "Here's the first five rows of our scraped data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "F9HFbo2rB4Wk",
        "outputId": "9cba1502-e2c2-4f2d-d30b-9d021ad93c78"
      },
      "source": [
        "stock = parse_batch(batch)\n",
        "stock.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>createdAt</th>\n",
              "      <th>title</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>categories</th>\n",
              "      <th>topics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-09-12T14:22:22.276Z</td>\n",
              "      <td>#請益 #請益 金融股存股疑問 官股 民股</td>\n",
              "      <td>如題，我知道官股存股首推兆豐金，配息又配股，可是會配股的股票代表股本要很大，且每年獲利如果沒...</td>\n",
              "      <td>請益</td>\n",
              "      <td>請益 | 金融 | 投資 | 官股 | 民營金控</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-09-12T13:59:36.831Z</td>\n",
              "      <td>#分享 9/12隔日當沖+波段分析</td>\n",
              "      <td>**無推薦跟單之意**，**純個人操作分享**，**損益自負**，本人當沖熱愛Tick流玩法...</td>\n",
              "      <td>分享</td>\n",
              "      <td>分析 | 台股 | 當沖 | 波段 | 技術分析</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-09-12T13:02:01.859Z</td>\n",
              "      <td>#分享 09/12類股分享-技術、籌碼分析</td>\n",
              "      <td>以下為個人技術及籌碼面分析，僅供參考，進出場請依照個人看法做決定。每日會有一篇更詳細的類股分...</td>\n",
              "      <td>分享</td>\n",
              "      <td>投資 | 股票 | 理財 | 台股 | 股市</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-09-12T11:55:08.194Z</td>\n",
              "      <td>#請益 長榮成本17元。11年前買的</td>\n",
              "      <td>請問一下。長榮海運股票10張。成本17元…11年前買的，，，忘記自己有 這檔股票。何時該出場賣掉？</td>\n",
              "      <td>請益</td>\n",
              "      <td>請益</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-09-12T11:25:08.604Z</td>\n",
              "      <td>#其他 簡訊越來越兇了啦</td>\n",
              "      <td>現在報明牌的簡訊越來越兇了~大家有發現嗎？啊每天那麼多封簡訊～一下ㄟ咪～一下candy，都不...</td>\n",
              "      <td>其他</td>\n",
              "      <td>兇 | 韭菜</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  createdAt  ...                    topics\n",
              "0  2021-09-12T14:22:22.276Z  ...  請益 | 金融 | 投資 | 官股 | 民營金控\n",
              "1  2021-09-12T13:59:36.831Z  ...  分析 | 台股 | 當沖 | 波段 | 技術分析\n",
              "2  2021-09-12T13:02:01.859Z  ...    投資 | 股票 | 理財 | 台股 | 股市\n",
              "3  2021-09-12T11:55:08.194Z  ...                        請益\n",
              "4  2021-09-12T11:25:08.604Z  ...                    兇 | 韭菜\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjObhrGm7SF9"
      },
      "source": [
        "# Getting forum names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k4KDMRR861j"
      },
      "source": [
        "As of Sep 11, 2021, there are in total 527 forums on Dcard. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qITNXwrE77y0",
        "outputId": "272f8609-c317-4932-fdd3-726802b5541a"
      },
      "source": [
        "import cloudscraper\n",
        "\n",
        "URL = \"https://www.dcard.tw/service/api/v2/forums\" \n",
        "scraper = cloudscraper.create_scraper() \n",
        "result = scraper.get(URL).json()\n",
        "len(result)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "527"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWQ7rmMC9xEU"
      },
      "source": [
        "For each forum, we can get its English name, Chinese name, and the number of users who subscribe to it, as shown in the following dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "n5UmJPxB77y0",
        "outputId": "b42a7e50-4644-420e-fb78-0fdf6a7e019b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "alias = [item.get('alias') for item in result]\n",
        "name = [item.get('name') for item in result]\n",
        "subscriptionCount = [item.get('subscriptionCount') for item in result]\n",
        "df = pd.DataFrame({\"name\": name, \"alias\": alias, \"subs\": subscriptionCount})\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>alias</th>\n",
              "      <th>subs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>午夜實驗室</td>\n",
              "      <td>midnightlab</td>\n",
              "      <td>1711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>時光膠囊</td>\n",
              "      <td>timecapsule</td>\n",
              "      <td>4284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>母親節</td>\n",
              "      <td>mother</td>\n",
              "      <td>373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>聖誕CiaoCiao</td>\n",
              "      <td>merryxmas</td>\n",
              "      <td>16807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>父親節</td>\n",
              "      <td>father</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>スポーツ</td>\n",
              "      <td>jp_sport</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>ミーム</td>\n",
              "      <td>jp_meme</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>MAMAMOO</td>\n",
              "      <td>mamamoo</td>\n",
              "      <td>4316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>無性戀</td>\n",
              "      <td>asexuality</td>\n",
              "      <td>769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>學士後</td>\n",
              "      <td>post_bachelor</td>\n",
              "      <td>592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>527 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           name          alias   subs\n",
              "0         午夜實驗室    midnightlab   1711\n",
              "1          時光膠囊    timecapsule   4284\n",
              "2           母親節         mother    373\n",
              "3    聖誕CiaoCiao      merryxmas  16807\n",
              "4           父親節         father    363\n",
              "..          ...            ...    ...\n",
              "522        スポーツ       jp_sport    110\n",
              "523         ミーム        jp_meme     48\n",
              "524     MAMAMOO        mamamoo   4316\n",
              "525         無性戀     asexuality    769\n",
              "526         學士後  post_bachelor    592\n",
              "\n",
              "[527 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3x-ILEN-zgb"
      },
      "source": [
        "Let's just focus on the top 20 forums in terms of subscriptions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "CYvIzs2R-0NH",
        "outputId": "ae0ad12e-464d-447f-c8d5-7d32a7950615"
      },
      "source": [
        "df.sort_values(by=['subs'], ascending=False, inplace=True)\n",
        "top20 = df.head(20)\n",
        "top20"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>alias</th>\n",
              "      <th>subs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>西斯</td>\n",
              "      <td>sex</td>\n",
              "      <td>639112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>穿搭</td>\n",
              "      <td>dressup</td>\n",
              "      <td>586341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>感情</td>\n",
              "      <td>relationship</td>\n",
              "      <td>583232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>美妝</td>\n",
              "      <td>makeup</td>\n",
              "      <td>487542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>梗圖</td>\n",
              "      <td>meme</td>\n",
              "      <td>476599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>美食</td>\n",
              "      <td>food</td>\n",
              "      <td>413792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>閒聊</td>\n",
              "      <td>talk</td>\n",
              "      <td>375398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>星座</td>\n",
              "      <td>horoscopes</td>\n",
              "      <td>364226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>時事</td>\n",
              "      <td>trending</td>\n",
              "      <td>358119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>理財</td>\n",
              "      <td>money</td>\n",
              "      <td>323464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>有趣</td>\n",
              "      <td>funny</td>\n",
              "      <td>295991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>Netflix</td>\n",
              "      <td>netflix</td>\n",
              "      <td>295088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>女孩</td>\n",
              "      <td>girl</td>\n",
              "      <td>289326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>YouTuber</td>\n",
              "      <td>youtuber</td>\n",
              "      <td>283766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>心情</td>\n",
              "      <td>mood</td>\n",
              "      <td>281588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>減肥</td>\n",
              "      <td>weight_loss</td>\n",
              "      <td>255195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>寵物</td>\n",
              "      <td>pet</td>\n",
              "      <td>248843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>股票</td>\n",
              "      <td>stock</td>\n",
              "      <td>239823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>健身</td>\n",
              "      <td>fitness</td>\n",
              "      <td>239310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>工作</td>\n",
              "      <td>job</td>\n",
              "      <td>231564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         name         alias    subs\n",
              "373        西斯           sex  639112\n",
              "224        穿搭       dressup  586341\n",
              "228        感情  relationship  583232\n",
              "217        美妝        makeup  487542\n",
              "233        梗圖          meme  476599\n",
              "273        美食          food  413792\n",
              "230        閒聊          talk  375398\n",
              "270        星座    horoscopes  364226\n",
              "346        時事      trending  358119\n",
              "340        理財         money  323464\n",
              "231        有趣         funny  295991\n",
              "287   Netflix       netflix  295088\n",
              "234        女孩          girl  289326\n",
              "212  YouTuber      youtuber  283766\n",
              "229        心情          mood  281588\n",
              "328        減肥   weight_loss  255195\n",
              "261        寵物           pet  248843\n",
              "447        股票         stock  239823\n",
              "327        健身       fitness  239310\n",
              "347        工作           job  231564"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnw0v45MAgVI"
      },
      "source": [
        "To get a better visual representation, let's plot out `top20` with `plotly`, which has better support for Chinese characters than `matplotlib`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "T9b_SE7H_X2P",
        "outputId": "b42ac0c9-138c-4d7d-8be9-38142825a1a5"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.bar(\n",
        "            top20, # df object\n",
        "            x=\"name\", \n",
        "            y=\"subs\",\n",
        "            color=\"subs\",\n",
        "            title=\"Dcard各版訂閱數\",\n",
        "            barmode=\"group\",\n",
        "            height=300,\n",
        "            )\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"c04146a9-c724-4c4d-94eb-4b8ee19ff552\" class=\"plotly-graph-div\" style=\"height:300px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"c04146a9-c724-4c4d-94eb-4b8ee19ff552\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'c04146a9-c724-4c4d-94eb-4b8ee19ff552',\n",
              "                        [{\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"name=%{x}<br>subs=%{marker.color}\", \"legendgroup\": \"\", \"marker\": {\"color\": [638362, 584443, 582358, 486337, 474964, 413011, 373710, 363787, 357286, 323081, 295694, 294429, 288908, 283508, 281066, 254336, 248602, 239127, 239059, 230879], \"coloraxis\": \"coloraxis\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"\\u897f\\u65af\", \"\\u7a7f\\u642d\", \"\\u611f\\u60c5\", \"\\u7f8e\\u599d\", \"\\u6897\\u5716\", \"\\u7f8e\\u98df\", \"\\u9592\\u804a\", \"\\u661f\\u5ea7\", \"\\u6642\\u4e8b\", \"\\u7406\\u8ca1\", \"\\u6709\\u8da3\", \"Netflix\", \"\\u5973\\u5b69\", \"YouTuber\", \"\\u5fc3\\u60c5\", \"\\u6e1b\\u80a5\", \"\\u5bf5\\u7269\", \"\\u80a1\\u7968\", \"\\u5065\\u8eab\", \"\\u5de5\\u4f5c\"], \"xaxis\": \"x\", \"y\": [638362, 584443, 582358, 486337, 474964, 413011, 373710, 363787, 357286, 323081, 295694, 294429, 288908, 283508, 281066, 254336, 248602, 239127, 239059, 230879], \"yaxis\": \"y\"}],\n",
              "                        {\"barmode\": \"group\", \"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"subs\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"height\": 300, \"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Dcard\\u5404\\u7248\\u8a02\\u95b1\\u6578\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"name\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"subs\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c04146a9-c724-4c4d-94eb-4b8ee19ff552');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtwwafjEg3a5"
      },
      "source": [
        "# Persisting data to SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VY03JsrG5J_"
      },
      "source": [
        "We'll use the `sqlite3` module to interact with a SQL database. First, the `sqlite3.connect()` function creates and then connects to a `.db` file, which we name `Dcard.db`. The next important thing to do is to create a table in the database. The `create_table` variable contains SQL syntax for creating a table named `Posts` with five columns, including `createdAt`, `title`, `excerpt`, `categories`, and `topics`. Crucially, we make the `createdAt` column the primary key so that posts with the same primary key will be ignored. The assumption here is that posts with the same timestamp are duplicates, though this might not be always the case. But in lack of info like post IDs, we'll just make do with timestamps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-rbEQqvTQMD"
      },
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('Dcard.db')  \n",
        "cursor = conn.cursor()\n",
        "create_table = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS Posts (\n",
        "    createdAt TIMESTAMP PRIMARY KEY ON CONFLICT IGNORE,\n",
        "    title,\n",
        "    excerpt, \n",
        "    categories, \n",
        "    topics);\n",
        "\"\"\"\n",
        "cursor.execute(create_table)  \n",
        "conn.commit()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm2mMITQR86V"
      },
      "source": [
        "Then we save the `stock` dataframe to the table we just created. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOQvqDibToxc"
      },
      "source": [
        "stock.to_sql('Posts', conn, if_exists='append', index=False) \n",
        "conn.commit()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTnLD_RHSE-1"
      },
      "source": [
        "To make sure the data is properly saved, let's load back the dataframe from the database. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6fpJqthYwej3",
        "outputId": "9b15f672-9a69-420e-bb0f-a265294b1e00"
      },
      "source": [
        "#collapse_output\n",
        "new_stock = pd.read_sql(\"SELECT * FROM Posts;\", conn)\n",
        "new_stock"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>createdAt</th>\n",
              "      <th>title</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>categories</th>\n",
              "      <th>topics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-09-12T14:22:22.276Z</td>\n",
              "      <td>#請益 #請益 金融股存股疑問 官股 民股</td>\n",
              "      <td>如題，我知道官股存股首推兆豐金，配息又配股，可是會配股的股票代表股本要很大，且每年獲利如果沒...</td>\n",
              "      <td>請益</td>\n",
              "      <td>請益 | 金融 | 投資 | 官股 | 民營金控</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-09-12T13:59:36.831Z</td>\n",
              "      <td>#分享 9/12隔日當沖+波段分析</td>\n",
              "      <td>**無推薦跟單之意**，**純個人操作分享**，**損益自負**，本人當沖熱愛Tick流玩法...</td>\n",
              "      <td>分享</td>\n",
              "      <td>分析 | 台股 | 當沖 | 波段 | 技術分析</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-09-12T13:02:01.859Z</td>\n",
              "      <td>#分享 09/12類股分享-技術、籌碼分析</td>\n",
              "      <td>以下為個人技術及籌碼面分析，僅供參考，進出場請依照個人看法做決定。每日會有一篇更詳細的類股分...</td>\n",
              "      <td>分享</td>\n",
              "      <td>投資 | 股票 | 理財 | 台股 | 股市</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-09-12T11:55:08.194Z</td>\n",
              "      <td>#請益 長榮成本17元。11年前買的</td>\n",
              "      <td>請問一下。長榮海運股票10張。成本17元…11年前買的，，，忘記自己有 這檔股票。何時該出場賣掉？</td>\n",
              "      <td>請益</td>\n",
              "      <td>請益</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-09-12T11:25:08.604Z</td>\n",
              "      <td>#其他 簡訊越來越兇了啦</td>\n",
              "      <td>現在報明牌的簡訊越來越兇了~大家有發現嗎？啊每天那麼多封簡訊～一下ㄟ咪～一下candy，都不...</td>\n",
              "      <td>其他</td>\n",
              "      <td>兇 | 韭菜</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-09-12T10:23:31.827Z</td>\n",
              "      <td>#分享 這週方舟機構ARK持股變化</td>\n",
              "      <td>分享這週（9/6 ~9/10）ARK持股變化，股票代碼-ARKQ 所屬ETF ARKQ，PA...</td>\n",
              "      <td>分享</td>\n",
              "      <td>投資 | 股票 | 美股 | ETF | 新聞</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2021-09-12T10:10:13.080Z</td>\n",
              "      <td>#分享 美股屑財報-本週財報與重點事件</td>\n",
              "      <td>.，IG ：美股餅乾屑，（週報固定每週日晚上6點更新），.，本週財報真的是有些無聊，但！要發...</td>\n",
              "      <td>分享</td>\n",
              "      <td>投資 | 股票 | 美股 | 股市 | 新手</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2021-09-12T09:55:47.721Z</td>\n",
              "      <td>#分享 明日當沖觀盤重點</td>\n",
              "      <td>歡迎大家追蹤我一起學習哦！</td>\n",
              "      <td>分享</td>\n",
              "      <td>股票 | 投資 | 理財 | 台股 | 當沖</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2021-09-12T09:47:05.404Z</td>\n",
              "      <td>#標的 聯電以及智原個股分析</td>\n",
              "      <td>這禮拜最後一次寫聯電發現大家真的對聯電很有興趣🤣那我們廢話不多說，馬上開始吧～聯電（2303...</td>\n",
              "      <td>標的</td>\n",
              "      <td>投資 | 股票 | 理財 | 台股 | 生活</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2021-09-12T08:03:31.864Z</td>\n",
              "      <td>#分享 狼王9月11日周六特輯</td>\n",
              "      <td>粉絲個股投票時間以及那些可以 中線佈局的股票們 ROKU ADSK CHWY SAVA SA...</td>\n",
              "      <td>分享</td>\n",
              "      <td>股票 | 美股 | 技術分析 | 狼王</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2021-09-12T05:46:00.967Z</td>\n",
              "      <td>#請益 關於這新聞，各位怎麼看？真的會影響嗎？</td>\n",
              "      <td>像這種新聞，對於股市的影響程度會有影響嗎？股市常常起起伏伏，真的很怕被這種新聞給狙擊</td>\n",
              "      <td>請益</td>\n",
              "      <td>請益 | 新聞 | 影響 | 投資 | 股票</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2021-09-12T05:26:03.419Z</td>\n",
              "      <td>#分享 分享個股看法 2390 3450</td>\n",
              "      <td>本次解析一下云辰和聯鈞，歡迎下方留言處討論，有任何地方標示錯誤請指教。我是股海一滴水，我們下...</td>\n",
              "      <td>分享</td>\n",
              "      <td>投資 | 股票 | 理財 | 台股 | 股市</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2021-09-12T04:44:13.512Z</td>\n",
              "      <td>#分享 時事分享—以股分交換作為企業佈局手段</td>\n",
              "      <td>大鯨魚吃小蝦米的故事，在資本市場其實很常發生，尤其是在歐美市場很流行以併購的方式，來壯大公司...</td>\n",
              "      <td>分享</td>\n",
              "      <td>時事 | 分享 | 股票 | 理財 | 新聞</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2021-09-12T03:57:18.993Z</td>\n",
              "      <td>#分享 Ashin老師9/10直播筆記</td>\n",
              "      <td></td>\n",
              "      <td>分享</td>\n",
              "      <td>老師 | 直播 | 筆記 | 股票 | 投資</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2021-09-12T03:33:35.076Z</td>\n",
              "      <td>#請益 海外券商閒置太久會有什麼法律上的問題嗎</td>\n",
              "      <td>如題目 最近想開始存美股了 哪其實上網查到很多有用的資訊了 剩下這個問題 如果閒置太久會有法...</td>\n",
              "      <td>請益</td>\n",
              "      <td>海外 | 券商 | 法律</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2021-09-12T02:57:04.070Z</td>\n",
              "      <td>#分享 搭上轉型列車-金融數位化</td>\n",
              "      <td>金融轉型勢必為未來趨勢，金融數位化，也是現在台灣金融產業正在著手進行的事情，而開發金也不難看...</td>\n",
              "      <td>分享</td>\n",
              "      <td>分享 | 金融 | 投資 | 股票 | 理財</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2021-09-12T02:38:43.280Z</td>\n",
              "      <td>#請益 【請教】XQ全球贏家APP 新功能-贏家選股使用心得</td>\n",
              "      <td>最近在XQ全球贏家的FB粉專上，看到他們的手機APP有推出一個全新的功能—贏家選股，聽說有高...</td>\n",
              "      <td>請益</td>\n",
              "      <td>投資 | app</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2021-09-12T02:00:14.107Z</td>\n",
              "      <td>#其他 本周紀錄</td>\n",
              "      <td>前幾天發文沒開到卡稱，再發一次紀錄，這邊只留短線操作紀錄，長線是定期定額ETF，一詮，欣興小...</td>\n",
              "      <td>其他</td>\n",
              "      <td>股票</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2021-09-11T18:23:49.445Z</td>\n",
              "      <td>#分享 各位到底知道股票為什麼會漲嗎？</td>\n",
              "      <td>我資歷大約12年，從高中時就知道，一定要學股票，因為多數的基金也是靠買股票賺，那何不自己學起...</td>\n",
              "      <td>分享</td>\n",
              "      <td>股票 | 分享</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2021-09-11T14:55:53.481Z</td>\n",
              "      <td>#分享 當沖Tick流分享</td>\n",
              "      <td>這兩天很多人問我這個問題，這邊來分享一下當沖Tick玩法，單純分享自身經驗、操作模式，沒有任...</td>\n",
              "      <td>分享</td>\n",
              "      <td>分享 | 股票 | 投資 | 當沖 | 分析</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2021-09-11T12:21:23.991Z</td>\n",
              "      <td>#分享 近期高殖利率標的</td>\n",
              "      <td>下週一一張國揚（2505）可以領1.5，下週二一張聲寶（1604）可以領2.5，目前這兩檔都...</td>\n",
              "      <td>分享</td>\n",
              "      <td>股息 | 分享 | 股利 | 股票 | 投資</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2021-09-11T12:17:40.308Z</td>\n",
              "      <td>#分享 編劇給我找出來</td>\n",
              "      <td>不囉嗦上圖，你們就看看麗珠，早在幾年前就已經看好航運了，你各位現在才追？附上人權啦，豪冷，2...</td>\n",
              "      <td>分享</td>\n",
              "      <td>投資 | 理財 | 台股 | 股票 | 股市</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2021-09-11T04:46:19.407Z</td>\n",
              "      <td>#分享 高伯精選股-2481多</td>\n",
              "      <td>單純看K棒來說 股價來打左點紅棒低點 停損小，現在進場大約目標就是110的位置 我自己停損大...</td>\n",
              "      <td>分享</td>\n",
              "      <td>股票 | 台股</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2021-09-11T02:42:41.606Z</td>\n",
              "      <td>#分享 東海彼得 - 9/10盤後分析</td>\n",
              "      <td>9/10 盤後分析，近期美股的走勢相對平穩，相較於一個月前的波動，可以說反差非常劇烈，最主要...</td>\n",
              "      <td>分享</td>\n",
              "      <td>投資 | 股票 | 理財 | 台股 | 股市</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2021-09-11T01:38:21.750Z</td>\n",
              "      <td>#分享 如我上週所判斷，那股市下週該如何..</td>\n",
              "      <td>上週分享的..也被我說中了..，以下是上週分享的觀點，那本週的狀況..，有關注的就會發現大盤...</td>\n",
              "      <td>分享</td>\n",
              "      <td>股市 | 當沖 | 波段 | 大盤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2021-09-11T01:09:59.029Z</td>\n",
              "      <td>#請益 定期定額買etf</td>\n",
              "      <td>想請教大家，我是股市新手，同時也是社會新鮮人，由於現在台股一直都在1w7左右，應該是台股最旺...</td>\n",
              "      <td>請益</td>\n",
              "      <td>etf | 投資</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2021-09-11T01:04:15.684Z</td>\n",
              "      <td>#分享 狼王9月10日美股復盤</td>\n",
              "      <td>震蕩的一周 貌似上週推演就提醒危險了~？今天我出手買貨了哦~ MA TSLA AAPL NF...</td>\n",
              "      <td>分享</td>\n",
              "      <td>美股 | 股票 | 技術分析 | 狼王</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2021-09-10T16:19:52.902Z</td>\n",
              "      <td>#標的 美股 Nvidia 輝達（$NVDA） 看多</td>\n",
              "      <td>今天要來談的標的是 $NVDA。如果你有在打遊戲，就一定會知道他們的超強顯卡。他們的顯卡不只...</td>\n",
              "      <td>標的</td>\n",
              "      <td>美股 | 股票 | 理財 | NVIDIA | 投資</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2021-09-10T15:55:10.143Z</td>\n",
              "      <td>#請益 請問這是600萬賠到300萬嗎</td>\n",
              "      <td>很謝謝大家的回覆但原本的資訊好像不太清楚，這是完整內容再麻煩大家解惑了謝謝，————————...</td>\n",
              "      <td>請益</td>\n",
              "      <td>股票 | 投資</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2021-09-10T15:51:03.972Z</td>\n",
              "      <td>#請益 #請益 請問這是哪家券商的介面</td>\n",
              "      <td>請問這是哪家券商的下單系統，可以顯示百分比！，跪求各位大神‍️‍️‍️</td>\n",
              "      <td>請益</td>\n",
              "      <td>請益 | 券商 | 股票 | 投資 | 台股</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   createdAt  ...                      topics\n",
              "0   2021-09-12T14:22:22.276Z  ...    請益 | 金融 | 投資 | 官股 | 民營金控\n",
              "1   2021-09-12T13:59:36.831Z  ...    分析 | 台股 | 當沖 | 波段 | 技術分析\n",
              "2   2021-09-12T13:02:01.859Z  ...      投資 | 股票 | 理財 | 台股 | 股市\n",
              "3   2021-09-12T11:55:08.194Z  ...                          請益\n",
              "4   2021-09-12T11:25:08.604Z  ...                      兇 | 韭菜\n",
              "5   2021-09-12T10:23:31.827Z  ...     投資 | 股票 | 美股 | ETF | 新聞\n",
              "6   2021-09-12T10:10:13.080Z  ...      投資 | 股票 | 美股 | 股市 | 新手\n",
              "7   2021-09-12T09:55:47.721Z  ...      股票 | 投資 | 理財 | 台股 | 當沖\n",
              "8   2021-09-12T09:47:05.404Z  ...      投資 | 股票 | 理財 | 台股 | 生活\n",
              "9   2021-09-12T08:03:31.864Z  ...         股票 | 美股 | 技術分析 | 狼王\n",
              "10  2021-09-12T05:46:00.967Z  ...      請益 | 新聞 | 影響 | 投資 | 股票\n",
              "11  2021-09-12T05:26:03.419Z  ...      投資 | 股票 | 理財 | 台股 | 股市\n",
              "12  2021-09-12T04:44:13.512Z  ...      時事 | 分享 | 股票 | 理財 | 新聞\n",
              "13  2021-09-12T03:57:18.993Z  ...      老師 | 直播 | 筆記 | 股票 | 投資\n",
              "14  2021-09-12T03:33:35.076Z  ...                海外 | 券商 | 法律\n",
              "15  2021-09-12T02:57:04.070Z  ...      分享 | 金融 | 投資 | 股票 | 理財\n",
              "16  2021-09-12T02:38:43.280Z  ...                    投資 | app\n",
              "17  2021-09-12T02:00:14.107Z  ...                          股票\n",
              "18  2021-09-11T18:23:49.445Z  ...                     股票 | 分享\n",
              "19  2021-09-11T14:55:53.481Z  ...      分享 | 股票 | 投資 | 當沖 | 分析\n",
              "20  2021-09-11T12:21:23.991Z  ...      股息 | 分享 | 股利 | 股票 | 投資\n",
              "21  2021-09-11T12:17:40.308Z  ...      投資 | 理財 | 台股 | 股票 | 股市\n",
              "22  2021-09-11T04:46:19.407Z  ...                     股票 | 台股\n",
              "23  2021-09-11T02:42:41.606Z  ...      投資 | 股票 | 理財 | 台股 | 股市\n",
              "24  2021-09-11T01:38:21.750Z  ...           股市 | 當沖 | 波段 | 大盤\n",
              "25  2021-09-11T01:09:59.029Z  ...                    etf | 投資\n",
              "26  2021-09-11T01:04:15.684Z  ...         美股 | 股票 | 技術分析 | 狼王\n",
              "27  2021-09-10T16:19:52.902Z  ...  美股 | 股票 | 理財 | NVIDIA | 投資\n",
              "28  2021-09-10T15:55:10.143Z  ...                     股票 | 投資\n",
              "29  2021-09-10T15:51:03.972Z  ...      請益 | 券商 | 股票 | 投資 | 台股\n",
              "\n",
              "[30 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpav8zbiipVU"
      },
      "source": [
        "# Testing the logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5gQVWdLKWAq"
      },
      "source": [
        "We'll use the `logging` module to create a log file named `logging.txt`, which can be configured by the `logging.basicConfig()` function. I'd like the logging format to be `[{timestamp}] {logging level} | {logging message}`, so the value of the `format` argument is `[%(asctime)s] %(levelname)s | %(message)s`. In addition, the format of the timestamp can be set up by the `datefmt` argument. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjYV0t0fhoCF"
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "        filename='logging.txt',\n",
        "        filemode=\"a\",\n",
        "        level=logging.INFO,\n",
        "        format=\"[%(asctime)s] %(levelname)s | %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    )"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPbYteFML08k"
      },
      "source": [
        "Let's test out three types of logs and check out the logging file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIW7ZtOYh4so",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad770a2-05a4-41f7-e290-a22428878474"
      },
      "source": [
        "logging.info(\"This is an info.\")\n",
        "logging.error(\"This an error!\")\n",
        "logging.warning(\"This is a warning!\")\n",
        "!head logging.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2021-09-12 08:31:31] INFO | This is an info.\n",
            "[2021-09-12 08:31:31] ERROR | This an error!\n",
            "[2021-09-12 08:31:31] WARNING | This is a warning!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJMp2UH_v2hV"
      },
      "source": [
        "# Testing the scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lUgvja-MMD-"
      },
      "source": [
        "We'll use the `schedule` library to activate our Dcard scraper at regular intervals. As a test for the scheduling function, the `scheduler.py` simply logs the current time to `logging.txt` every three seconds. The first step for scheduling a job is to define a function, which is named `job()` in this case. Then the job can be put on schedule by simply calling the `schedule.every({num}).{unit}.do({job})` function, where `{num}` is an integer, `{unit}` a string for unit of time like `seconds`, `minutes` or `hours`, and finally `{job}` the function scheduled to run. Finally, if we call the `schedule.run_pending()` function within a `while` loop, the program will run indefinitely. Run the following cell to create `scheduler.py`.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llmKEVZsAe9x"
      },
      "source": [
        "#collapse\n",
        "%%writefile scheduler.py\n",
        "\n",
        "import schedule \n",
        "import time\n",
        "from datetime import datetime\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "        filename='logging.txt',\n",
        "        filemode=\"a\",\n",
        "        level=logging.INFO,\n",
        "        format=\"[%(asctime)s] %(levelname)s | %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    )\n",
        "\n",
        "def job():\n",
        "    now = datetime.now()\n",
        "    message = f\"Hello, the current time is {now}.\"\n",
        "    logging.info(message)\n",
        "\n",
        "schedule.every(3).seconds.do(job)\n",
        "schedule.run_all() #Without this line, the job will start in 3 seconds rather than immediately. \n",
        "\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zJZx2cYV1WS"
      },
      "source": [
        "Now run `python scheduler.py` in the terminal to test the scheduler, which will keep running unless stopped! If you run it for a while and then stop it, `logging.txt` will look something like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhVtATbvKIJL",
        "outputId": "4477f8ed-c31b-492e-e06a-8c46a0e89978"
      },
      "source": [
        "!tail logging.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2021-09-12 08:31:31] ERROR | This an error!\n",
            "[2021-09-12 08:31:31] WARNING | This is a warning!\n",
            "[2021-09-12 08:37:40] INFO | Hello, the current time is 2021-09-12 08:37:40.643431.\n",
            "[2021-09-12 08:37:43] INFO | Hello, the current time is 2021-09-12 08:37:43.647108.\n",
            "[2021-09-12 08:37:46] INFO | Hello, the current time is 2021-09-12 08:37:46.651045.\n",
            "[2021-09-12 08:37:49] INFO | Hello, the current time is 2021-09-12 08:37:49.655009.\n",
            "[2021-09-12 08:37:52] INFO | Hello, the current time is 2021-09-12 08:37:52.658558.\n",
            "[2021-09-12 08:37:55] INFO | Hello, the current time is 2021-09-12 08:37:55.662393.\n",
            "[2021-09-12 08:37:58] INFO | Hello, the current time is 2021-09-12 08:37:58.666367.\n",
            "[2021-09-12 08:38:01] INFO | Hello, the current time is 2021-09-12 08:38:01.669397.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgm5WIJtVokU"
      },
      "source": [
        "Now that we've covered all the components we need, let's remove `logging.txt` and `Dcard.db` to start afresh and put everything together. To do that, just run `rm logging.txt Dcard.db` in the terminal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2eojvnJ_xu8"
      },
      "source": [
        "# Putting everything together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99AO_dG1dbbV"
      },
      "source": [
        "Finally, it's time to put everything together. Run the following cell to create `Dcard_scraper.py`. The only thing new here is that this time around we are going to scrape multiple forums rather than just one. So we first create a dictionary called `forums`, where the keys are forum names in English and the values their equivalents in Chinese. We'll need the English forum names to get the API full URLs. Plus, we add two more columns in the `Posts` tabel of `Dcard.db` (i.e. `forum_en` and `forum_zh`) to store the forum names. The `main()` function takes care of iteration over every forum stored in the `forums` variable as well as some basic exception handling. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdaWsOeTXHAo"
      },
      "source": [
        "#collapse\n",
        "%%writefile Dcard_scraper.py\n",
        "\n",
        "import cloudscraper\n",
        "import logging\n",
        "import pandas as pd\n",
        "from random import randint\n",
        "import schedule\n",
        "import sqlite3\n",
        "import time\n",
        "\n",
        "# Configuring the logging.txt file\n",
        "logging.basicConfig(\n",
        "        filename='logging.txt',\n",
        "        filemode=\"a\",\n",
        "        level=logging.INFO,\n",
        "        format=\"[%(asctime)s] %(levelname)s | %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "    )\n",
        "\n",
        "# Dcard API base URL\n",
        "baseURL = \"https://www.dcard.tw/service/api/v2/forums/\"\n",
        "\n",
        "# List of forums. Add as many as you want. Here I'm just picking 18 forums. \n",
        "forums = {\n",
        "    \"dressup\": \"穿搭\",\n",
        "    \"relationship\": \"感情\",\n",
        "    \"makeup\": \"美妝\",\n",
        "    \"food\": \"美食\",\n",
        "    \"horoscopes\": \"星座\",\n",
        "    \"talk\": \"閒聊\",\n",
        "    \"trending\": \"時事\",\n",
        "    \"money\": \"理財\",\n",
        "    \"funny\": \"有趣\",\n",
        "    \"girl\": \"女孩\",\n",
        "    \"netflix\": \"Netflix\",\n",
        "    \"youtuber\": \"YouTuber\",\n",
        "    \"mood\": \"心情\",\n",
        "    \"pet\": \"寵物\",\n",
        "    \"weight_loss\": \"減肥\",\n",
        "    \"fitness\": \"健身\",\n",
        "    \"stock\": \"股票\",\n",
        "    \"job\": \"工作\",\n",
        "}\n",
        "\n",
        "# Creating a SQLite database and a table named Posts\n",
        "conn = sqlite3.connect('Dcard.db')  \n",
        "cursor = conn.cursor()\n",
        "create_table = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS Posts (\n",
        "    createdAt TIMESTAMP PRIMARY KEY ON CONFLICT IGNORE,\n",
        "    title,\n",
        "    excerpt, \n",
        "    categories, \n",
        "    topics,\n",
        "    forum_en,\n",
        "    forum_zh);\n",
        "\"\"\"\n",
        "cursor.execute(create_table)  \n",
        "conn.commit()\n",
        "\n",
        "# Parsing a batch of JSON response and creating a dataframe out of it\n",
        "def parse_batch(batch):\n",
        "    createdAt = [item.get('createdAt', 'None') for item in batch]\n",
        "    title = [item.get('title', 'None') for item in batch]\n",
        "    excerpt = [item.get('excerpt', 'None') for item in batch]\n",
        "    dummy = []\n",
        "    categories = [item.get('categories', dummy) for item in batch] # every element is a list\n",
        "    topics = [item.get('topics', dummy) for item in batch] # every element is a list\n",
        "    data = {\n",
        "        'createdAt': createdAt,\n",
        "        'title': title,\n",
        "        'excerpt': excerpt,\n",
        "        'categories': categories,\n",
        "        'topics': topics,    \n",
        "        }\n",
        "    df = pd.DataFrame(data)\n",
        "    df.loc [:, 'categories'] = df['categories'].apply(lambda x: \" | \".join(x))\n",
        "    df.loc [:, 'topics'] = df['topics'].apply(lambda x: \" | \".join(x))\n",
        "    return df\n",
        "\n",
        "# Main scraper\n",
        "def main():\n",
        "    scraper = cloudscraper.create_scraper()\n",
        "    sec = randint(1, 15)\n",
        "\n",
        "    for forum_en, forum_zh in forums.items():\n",
        "        result = scraper.get(baseURL + forum_en + \"/posts\")\n",
        "\n",
        "        if result.status_code == 200:\n",
        "            batch = result.json()\n",
        "            try:\n",
        "                df = parse_batch(batch)\n",
        "                df[\"forum_en\"] = forum_en\n",
        "                df[\"forum_zh\"] = forum_zh\n",
        "                logging.info(f\"{df.shape[0]} posts on {forum_en} have been scraped.\")\n",
        "                df.to_sql(\"Posts\", conn, if_exists=\"append\", index=False)\n",
        "                conn.commit()\n",
        "                cursor.execute(f\"SELECT COUNT(*) from Posts;\")\n",
        "                rows = cursor.fetchone()[0]\n",
        "                logging.info(f\"There are in total {rows} posts in the DB.\")\n",
        "            except Exception as argument:\n",
        "                logging.error(argument)\n",
        "        else:\n",
        "            logging.error(f\"The request on {forum_en} was unsuccessful.\")\n",
        "\n",
        "        time.sleep(sec)\n",
        "\n",
        "# Setting the scraping interval\n",
        "schedule.every(30).minutes.do(main)  \n",
        "schedule.run_all()\n",
        "\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcnrdWsgijM0"
      },
      "source": [
        "Now it's harvest time! Run `python Dcard_scraper.py` in the terminal to start the scraper, which will run every 30 minutes unless stopped. If everything goes well, the `logging.txt` file will look like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5wD_oWsjsrQ",
        "outputId": "b3758368-e50d-4e93-f57e-0aaf1e933e1c"
      },
      "source": [
        "!tail logging.txt"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2021-09-12 14:44:21] INFO | 30 posts on pet have been scraped.\n",
            "[2021-09-12 14:44:21] INFO | There are in total 420 posts in the DB.\n",
            "[2021-09-12 14:44:33] INFO | 30 posts on weight_loss have been scraped.\n",
            "[2021-09-12 14:44:33] INFO | There are in total 450 posts in the DB.\n",
            "[2021-09-12 14:44:46] INFO | 30 posts on fitness have been scraped.\n",
            "[2021-09-12 14:44:46] INFO | There are in total 480 posts in the DB.\n",
            "[2021-09-12 14:44:58] INFO | 30 posts on stock have been scraped.\n",
            "[2021-09-12 14:44:58] INFO | There are in total 510 posts in the DB.\n",
            "[2021-09-12 14:45:10] INFO | 30 posts on job have been scraped.\n",
            "[2021-09-12 14:45:10] INFO | There are in total 540 posts in the DB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzx4lyaGjw0b"
      },
      "source": [
        "And here's the result of our hard work! In my case, I ran the scraper for around 3 minutes and got 540 posts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "FVHug18leePy",
        "outputId": "e8f97501-85a4-4c76-e35c-724f7e37ea94"
      },
      "source": [
        "#collapse_output\n",
        "conn = sqlite3.connect('Dcard.db')  \n",
        "data = pd.read_sql(\"SELECT * FROM Posts;\", conn)\n",
        "data"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>createdAt</th>\n",
              "      <th>title</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>categories</th>\n",
              "      <th>topics</th>\n",
              "      <th>forum_en</th>\n",
              "      <th>forum_zh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-09-12T14:35:07.314Z</td>\n",
              "      <td>問air force真假</td>\n",
              "      <td>️第一次發文，不知道發在穿搭版可不可以，排版不好請見諒若有違反規定會刪文，前陣子在蝦皮購買一...</td>\n",
              "      <td></td>\n",
              "      <td>問 | force | 真假 | 穿搭 | 蝦皮</td>\n",
              "      <td>dressup</td>\n",
              "      <td>穿搭</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-09-12T14:18:12.598Z</td>\n",
              "      <td>疫情買的衣服分享🙌淘寶居多</td>\n",
              "      <td>我是女生！，本人156/45，衣服都蠻平價的～1⃣️，洋裝：淘寶，包：Toae，鞋子：淘寶，...</td>\n",
              "      <td></td>\n",
              "      <td>疫情 | 衣服 | 分享</td>\n",
              "      <td>dressup</td>\n",
              "      <td>穿搭</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-09-12T13:56:35.559Z</td>\n",
              "      <td>我與室友的穿搭分享</td>\n",
              "      <td>趁颱風天沒事來分享我跟室友的穿搭～（沒戴口罩的是疫情前拍的呦），先分享室友的，1. 單車褲穿...</td>\n",
              "      <td></td>\n",
              "      <td>穿搭 | 女生穿搭</td>\n",
              "      <td>dressup</td>\n",
              "      <td>穿搭</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-09-12T13:54:26.217Z</td>\n",
              "      <td>#問 求包包的關鍵字</td>\n",
              "      <td>想請問俞丁背的這種包叫什麼名字，有點像送子鳥包，可是我在蝦皮都找不到類似的，或是有人在哪些網...</td>\n",
              "      <td></td>\n",
              "      <td>包包 | 關鍵字</td>\n",
              "      <td>dressup</td>\n",
              "      <td>穿搭</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-09-12T13:36:51.407Z</td>\n",
              "      <td>#問 北臉包包代購</td>\n",
              "      <td>小妹想買這個包包很久了，但北臉的包包是第一次購買，怕買到仿冒品，想請教各位版友，有推薦的賣家...</td>\n",
              "      <td></td>\n",
              "      <td>問 | 北臉 | 包包 | 真假</td>\n",
              "      <td>dressup</td>\n",
              "      <td>穿搭</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>2021-09-12T12:37:12.067Z</td>\n",
              "      <td>轉職 通勤or租屋請益</td>\n",
              "      <td>大家好，小妹預計10月初到新公司（林口）報到，家住新北汐止，目前煩惱要開車通勤（40-50分...</td>\n",
              "      <td></td>\n",
              "      <td>通勤 | 租屋</td>\n",
              "      <td>job</td>\n",
              "      <td>工作</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>2021-09-12T12:24:17.122Z</td>\n",
              "      <td>早八晚五工作</td>\n",
              "      <td>請問有什麼工作是早八晚五，（正職），但是放假不是見紅就休？而是排休的？</td>\n",
              "      <td></td>\n",
              "      <td>工作 | 工作經驗</td>\n",
              "      <td>job</td>\n",
              "      <td>工作</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>2021-09-12T12:20:05.422Z</td>\n",
              "      <td>#問 會問生活體驗是希望得到什麼答案</td>\n",
              "      <td>如題，面試時公司給了一張基本資料表，第一個問我對“工作”（沒確切說是應徵職位還是工作本身）的...</td>\n",
              "      <td></td>\n",
              "      <td>工作 | 求職</td>\n",
              "      <td>job</td>\n",
              "      <td>工作</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>2021-09-12T12:11:54.507Z</td>\n",
              "      <td>工作幾年後還會想回學校讀書嗎？</td>\n",
              "      <td>以前老師常說要讀就一口氣讀不要中斷不然很難工作後再回來讀，我自己是工作2年後離職準備一年考上...</td>\n",
              "      <td></td>\n",
              "      <td>學校 | 讀書 | 工作</td>\n",
              "      <td>job</td>\n",
              "      <td>工作</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>2021-09-12T12:10:44.789Z</td>\n",
              "      <td>#問 大學研究中心徵才</td>\n",
              "      <td>本人為私立應屆，最近在求職中，看到很多四大四中的研究中心之類的在徵才，也有投遞履歷約面試，職...</td>\n",
              "      <td></td>\n",
              "      <td>徵才 | 問 | 應屆畢業生</td>\n",
              "      <td>job</td>\n",
              "      <td>工作</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>540 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    createdAt               title  ... forum_en forum_zh\n",
              "0    2021-09-12T14:35:07.314Z        問air force真假  ...  dressup       穿搭\n",
              "1    2021-09-12T14:18:12.598Z       疫情買的衣服分享🙌淘寶居多  ...  dressup       穿搭\n",
              "2    2021-09-12T13:56:35.559Z           我與室友的穿搭分享  ...  dressup       穿搭\n",
              "3    2021-09-12T13:54:26.217Z          #問 求包包的關鍵字  ...  dressup       穿搭\n",
              "4    2021-09-12T13:36:51.407Z           #問 北臉包包代購  ...  dressup       穿搭\n",
              "..                        ...                 ...  ...      ...      ...\n",
              "535  2021-09-12T12:37:12.067Z         轉職 通勤or租屋請益  ...      job       工作\n",
              "536  2021-09-12T12:24:17.122Z              早八晚五工作  ...      job       工作\n",
              "537  2021-09-12T12:20:05.422Z  #問 會問生活體驗是希望得到什麼答案  ...      job       工作\n",
              "538  2021-09-12T12:11:54.507Z     工作幾年後還會想回學校讀書嗎？  ...      job       工作\n",
              "539  2021-09-12T12:10:44.789Z         #問 大學研究中心徵才  ...      job       工作\n",
              "\n",
              "[540 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsW8eLQLk8H0"
      },
      "source": [
        "# Recap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjZbqFVxlH0J"
      },
      "source": [
        "In this post, we used `cloudscraper` to scrape data from Dcard and `schedule` to regularly run the scraper. Both are powerful and elegant libraries that can be applied to any other scraping project. As a side note, I was able to run the Dcard scraper for several days in a row without having any error!"
      ]
    }
  ]
}
